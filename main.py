# Arquivo: main.py (Vers√£o 8 - Gera√ß√£o com Salvamento Autom√°tico no Firestore)

from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
import firebase_admin
from firebase_admin import credentials, firestore
from contextlib import asynccontextmanager
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions
from dotenv import load_dotenv
from pydantic import BaseModel
import json
import fitz  # PyMuPDF para processamento de PDF
import time
import psutil  # Para m√©tricas do sistema
import threading
import asyncio
from datetime import datetime, timedelta
from collections import defaultdict, deque
import logging
from typing import Optional, Dict, Any, List, Union

# --- Carregamento de Vari√°veis de Ambiente ---
load_dotenv()
from web_search import search_web

# --- Constantes do Gemini FinishReason ---
FINISH_REASON_NAMES = {
    0: "FINISH_REASON_UNSPECIFIED",
    1: "STOP",  # Ponto de parada natural
    2: "MAX_TOKENS",  # Limite m√°ximo de tokens
    3: "SAFETY",  # Bloqueado por seguran√ßa
    4: "RECITATION",  # Bloqueado por recita√ß√£o
    5: "LANGUAGE",  # Idioma n√£o suportado  
    6: "OTHER",  # Motivo desconhecido
    7: "BLOCKLIST",  # Termos proibidos
    8: "PROHIBITED_CONTENT",  # Conte√∫do proibido
    9: "SPII",  # Informa√ß√µes pessoais sens√≠veis
    10: "MALFORMED_FUNCTION_CALL",  # Chamada de fun√ß√£o inv√°lida
}

# --- Vari√°veis Globais ---
db = None
firebase_mock_mode = False
AGENT_RULES: Dict[str, Any] = {}
PARSED_REFERENCIAS: Dict[str, str] = {}  # Nova vari√°vel para armazenar se√ß√µes parsed
GEMINI_CONFIGS: Dict[str, List[Dict[str, str]]] = {}
LOCAL_MEMORY_SYSTEM: Dict[str, Any] = {}  # Nova vari√°vel para sistema de mem√≥ria local
VERSION_SYSTEM: Dict[str, Any] = {}  # Nova vari√°vel para sistema de versionamento
MONITORING_SYSTEM: Dict[str, Any] = {}  # Nova vari√°vel para sistema de monitoramento

# --- Modelos de Dados (Pydantic) ---
class CreateStationRequest(BaseModel):
    tema: str
    especialidade: str

class GenerateFinalStationRequest(BaseModel):
    resumo_clinico: str
    proposta_escolhida: str
    tema: str
    especialidade: str

class AnalyzeStationRequest(BaseModel):
    station_id: str
    feedback: str | None = None

class ApplyAuditRequest(BaseModel):
    station_id: str
    analysis_result: str

class UpdateRulesRequest(BaseModel):
    new_rule: str
    context: str | None = None
    category: str | None = None

# --- Fun√ß√£o de Extra√ß√£o de PDF ---
def extract_pdf_content_structured(pdf_bytes: bytes, tema: str) -> str:
    """
    Extrai o conte√∫do do PDF de forma estruturada conforme as orienta√ß√µes espec√≠ficas.
    Foca no tema/doen√ßa especificado e segue a estrutura solicitada.
    """
    try:
        # Abrir o PDF a partir dos bytes
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        
        # Extrair todo o texto do PDF
        full_text = ""
        toc_text = ""
        
        # Tentar extrair o √≠ndice/sum√°rio se existir
        toc = doc.get_toc()  # type: ignore
        if toc:
            toc_text = "√çNDICE/SUM√ÅRIO ENCONTRADO:\n"
            for level, title, page in toc:
                toc_text += f"{'  ' * (level-1)}- {title} (p√°gina {page})\n"
            toc_text += "\n"
        
        # Extrair texto de todas as p√°ginas
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            page_text = page.get_text()  # type: ignore
            full_text += f"\n--- P√ÅGINA {page_num + 1} ---\n"
            full_text += page_text
        
        doc.close()
        
        # Estruturar o conte√∫do conforme solicitado
        structured_content = f"""
AN√ÅLISE ESTRUTURADA DO PDF PARA O TEMA: {tema.upper()}

{toc_text}

INSTRU√á√ïES DE EXTRA√á√ÉO:
- Foque especificamente no tema/doen√ßa: {tema}
- Extraia apenas conte√∫do relevante para cria√ß√£o de esta√ß√µes m√©dicas
- Identifique se√ß√µes sobre: conceitos, classifica√ß√£o, fatores de risco, quadro cl√≠nico, diagn√≥stico, tratamento
- Ignore conte√∫do n√£o relacionado ao tema principal

CONTE√öDO COMPLETO DO PDF:
{full_text}

ORIENTA√á√ïES PARA AN√ÅLISE:
1. Busque no √≠ndice t√≥picos relacionados ao tema: {tema}
2. Extraia conceitos iniciais relevantes ao tema
3. Identifique subt√≥picos como: classifica√ß√£o, fatores de risco, preven√ß√£o, quadro cl√≠nico, diagn√≥stico, tratamento
4. Localize refer√™ncias bibliogr√°ficas
5. Busque considera√ß√µes finais relacionadas ao tema
"""
        
        return structured_content
        
    except Exception as e:
        raise Exception(f"Erro ao processar PDF: {str(e)}")

# --- Fun√ß√£o de Parser de Referencias ---
def parse_referencias_md(referencias_content: str) -> dict:
    """
    Parser que divide o conte√∫do do referencias.md em se√ß√µes espec√≠ficas.
    Retorna um dicion√°rio com as se√ß√µes identificadas para uso otimizado nos prompts.
    """
    if not referencias_content:
        print("‚ö†Ô∏è Conte√∫do de referencias.md est√° vazio")
        return {}
    
    try:
        sections = {}
        lines = referencias_content.split('\n')
        current_section = None
        current_content = []
        
        print("üîç Iniciando parsing do referencias.md...")
        
        for line in lines:
            # Detectar in√≠cio das se√ß√µes principais
            if line.startswith('# GUIA MESTRE') or line.startswith('. PRINC√çPIOS FUNDAMENTAIS'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'principios_fundamentais'
                current_content = [line]
                
            elif line.startswith('## 1. ARQUITETURA DAS ESTA√á√ïES'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'arquitetura_estacoes'
                current_content = [line]
                
            elif line.startswith('## 2. DIRETRIZES PARA TAREFAS'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'diretrizes_tarefas'
                current_content = [line]
                
            elif line.startswith('## 3. TAREFAS PRINCIPAIS POR ESPECIALIDADE'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'tarefas_especialidade'
                current_content = [line]
                
            elif line.startswith('### **4.1. REGRAS B√ÅSICAS'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'regras_basicas_ator'
                current_content = [line]
                
            elif line.startswith('### **4.2. REGRAS OBRIGAT√ìRIAS'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'regras_contextos_ator'
                current_content = [line]
                
            elif line.startswith('## 4. O ROTEIRO DO ATOR'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'roteiro_ator_completo'
                current_content = [line]
                
            elif line.startswith('## 5. BANCO DE SEMIOLOGIA'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'banco_semiologia'
                current_content = [line]
                
            elif line.startswith('## 6. TIPOS DE IMPRESSOS'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'tipos_impressos'
                current_content = [line]
                
            elif line.startswith('## 7. DIRETRIZES AVAN√áADAS PARA CONSTRU√á√ÉO DO PEP'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'diretrizes_pep'
                current_content = [line]
                
            elif line.startswith('## 8. ESTRUTURAS ESPEC√çFICAS POR ESPECIALIDADE'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'estruturas_especialidade'
                current_content = [line]
                
            elif line.startswith('## 9. CHECKLIST DE VALIDA√á√ÉO'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'checklist_validacao'
                current_content = [line]
                
            elif line.startswith('## 10. REGRA APRENDIDA'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = 'regra_aprendida'
                current_content = [line]
                
            else:
                # Adicionar linha ao conte√∫do da se√ß√£o atual
                if current_section:
                    current_content.append(line)
        
        # Adicionar a √∫ltima se√ß√£o
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        print(f"‚úÖ Parser conclu√≠do! {len(sections)} se√ß√µes identificadas:")
        for key in sections.keys():
            print(f"   üìÑ {key}: {len(sections[key])} caracteres")
        
        return sections
        
    except Exception as e:
        print(f"‚ùå Erro ao fazer parsing do referencias.md: {e}")
        return {}

# --- Sistema H√≠brido de Mem√≥ria Local ---
def load_local_memory_config():
    """Carrega a configura√ß√£o do sistema de mem√≥ria local"""
    try:
        with open('memoria/config_memoria.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar config_memoria.json: {e}")
        return {}

def load_local_file(file_path):
    """Carrega conte√∫do de arquivo local com encoding UTF-8"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar arquivo {file_path}: {e}")
        return ""

def initialize_local_memory_system():
    """Inicializa o sistema h√≠brido de mem√≥ria local"""
    global LOCAL_MEMORY_SYSTEM
    try:
        print("üß† Inicializando sistema h√≠brido de mem√≥ria local...")
        
        # Carregar configura√ß√£o
        config = load_local_memory_config()
        if not config:
            print("‚ùå Falha ao carregar configura√ß√£o - usando sistema antigo")
            return False
            
        LOCAL_MEMORY_SYSTEM['config'] = config
        sistema = config.get('sistema_memoria', {})
        estrutura = sistema.get('estrutura', {})
        
        # Carregar arquivos base
        print("üìÑ Carregando arquivos base...")
        LOCAL_MEMORY_SYSTEM['referencias_base'] = load_local_file(estrutura.get('referencias_base', ''))
        LOCAL_MEMORY_SYSTEM['gabarito_template'] = load_local_file(estrutura.get('gabarito_template', ''))
        
        # Carregar contextos otimizados por fase
        print("üìÅ Carregando contextos otimizados...")
        contextos = estrutura.get('contexto_otimizado', {})
        LOCAL_MEMORY_SYSTEM['contextos'] = {}
        for fase, arquivo in contextos.items():
            LOCAL_MEMORY_SYSTEM['contextos'][fase] = load_local_file(arquivo)
            
        # Carregar aprendizados do usu√°rio
        print("üéì Carregando aprendizados do usu√°rio...")
        try:
            with open(estrutura.get('aprendizados_usuario', ''), 'r', encoding='utf-8') as f:
                LOCAL_MEMORY_SYSTEM['aprendizados'] = json.load(f)
        except:
            LOCAL_MEMORY_SYSTEM['aprendizados'] = []
            
        print("‚úÖ Sistema h√≠brido de mem√≥ria local inicializado com sucesso!")
        economia = sistema.get('reducao_tokens', {}).get('economia', 'N/A')
        print(f"üí∞ Economia estimada: {economia}")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao inicializar sistema local: {e}")
        return False

def get_context_for_phase(phase_number):
    """Retorna contexto otimizado para uma fase espec√≠fica"""
    if not LOCAL_MEMORY_SYSTEM:
        return ""
        
    try:
        config = LOCAL_MEMORY_SYSTEM.get('config', {})
        regras = config.get('sistema_memoria', {}).get('regras_carregamento', {})
        
        # Arquivos que sempre devem ser carregados
        sempre_carregar = regras.get('sempre_carregar', [])
        contexto_completo = ""
        
        # Adicionar refer√™ncias base se sempre necess√°rio
        if 'referencias_base' in sempre_carregar:
            contexto_completo += LOCAL_MEMORY_SYSTEM.get('referencias_base', '')
            
        # Carregar contextos espec√≠ficos da fase
        carregar_por_fase = regras.get('carregar_por_fase', {})
        fase_str = str(phase_number)
        
        if fase_str in carregar_por_fase:
            arquivos_fase = carregar_por_fase[fase_str]
            
            for arquivo in arquivos_fase:
                if arquivo == 'gabarito_template':
                    # Gabarito JSON √© carregado separadamente
                    continue
                elif arquivo.startswith('fase'):
                    # Contexto otimizado de fase
                    conteudo = LOCAL_MEMORY_SYSTEM.get('contextos', {}).get(arquivo, '')
                    if conteudo:
                        contexto_completo += f"\n\n--- {arquivo.upper().replace('_', ' ')} ---\n"
                        contexto_completo += conteudo
        
        # Sempre adicionar aprendizados do usu√°rio se houver (novo formato)
        aprendizados = LOCAL_MEMORY_SYSTEM.get('aprendizados', [])
        if aprendizados:
            contexto_completo += "\n\n" + format_learnings_for_context(aprendizados)
                
        print(f"üìä Fase {phase_number}: {len(contexto_completo)} caracteres carregados")
        return contexto_completo
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao gerar contexto para fase {phase_number}: {e}")
        return ""

def get_gabarito_template():
    """Retorna o template do gabarito JSON local"""
    return LOCAL_MEMORY_SYSTEM.get('gabarito_template', '{}')

# --- Sistema de Aprendizado Autom√°tico ---
def categorize_learning(new_rule: str, context: Optional[str] = None) -> str:
    """Categoriza automaticamente um novo aprendizado"""
    rule_lower = new_rule.lower()
    
    # Palavras-chave para categoriza√ß√£o
    if any(word in rule_lower for word in ['nunca', 'n√£o', 'evitar', 'proibido', 'incorreto']):
        return "restricao"
    elif any(word in rule_lower for word in ['sempre', 'obrigat√≥rio', 'deve', 'essencial', 'regra']):
        return "obrigatorio"
    elif any(word in rule_lower for word in ['preferir', 'melhor', 'recomendado', 'ideal']):
        return "preferencia"
    elif any(word in rule_lower for word in ['novo', 'adicionar', 'incluir', 'criar']):
        return "novo_padrao"
    elif any(word in rule_lower for word in ['corrigir', 'erro', 'problema', 'bug']):
        return "correcao"
    elif any(word in rule_lower for word in ['formato', 'estrutura', 'template', 'padr√£o']):
        return "formatacao"
    else:
        return "geral"

def save_learning(new_rule: str, context: Optional[str] = None, category: Optional[str] = None) -> bool:
    """Salva um novo aprendizado no sistema local"""
    try:
        if not LOCAL_MEMORY_SYSTEM:
            print("‚ö†Ô∏è Sistema local n√£o inicializado, salvando no Firestore apenas")
            return False
            
        # Categorizar automaticamente se n√£o fornecida
        if not category:
            category = categorize_learning(new_rule, context)
            
        # Criar registro do aprendizado
        learning_entry = {
            "timestamp": json.dumps({"$date": {"$numberLong": str(int(__import__('time').time() * 1000))}}),
            "rule": new_rule,
            "context": context or "Sem contexto espec√≠fico",
            "category": category,
            "source": "user_feedback"
        }
        
        # Carregar aprendizados existentes
        aprendizados_file = "memoria/aprendizados_usuario.jsonl"
        aprendizados = LOCAL_MEMORY_SYSTEM.get('aprendizados', [])
        
        # Adicionar novo aprendizado
        aprendizados.append(learning_entry)
        LOCAL_MEMORY_SYSTEM['aprendizados'] = aprendizados
        
        # Salvar no arquivo local
        with open(aprendizados_file, 'w', encoding='utf-8') as f:
            json.dump(aprendizados, f, ensure_ascii=False, indent=2)
            
        print(f"‚úÖ Aprendizado salvo - Categoria: {category}")
        print(f"üìù Regra: {new_rule[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao salvar aprendizado: {e}")
        return False

def get_recent_learnings(limit: int = 10) -> list:
    """Retorna os aprendizados mais recentes"""
    if not LOCAL_MEMORY_SYSTEM:
        return []
        
    aprendizados = LOCAL_MEMORY_SYSTEM.get('aprendizados', [])
    return aprendizados[-limit:] if aprendizados else []

def format_learnings_for_context(learnings: list) -> str:
    """Formata aprendizados para incluir no contexto"""
    if not learnings:
        return ""
        
    formatted = "## REGRAS APRENDIDAS AUTOMATICAMENTE\n\n"
    
    # Agrupar por categoria
    by_category = {}
    for learning in learnings:
        category = learning.get('category', 'geral')
        if category not in by_category:
            by_category[category] = []
        by_category[category].append(learning)
    
    # Formata√ß√£o por categoria
    category_names = {
        'restricao': 'üö´ RESTRI√á√ïES',
        'obrigatorio': '‚úÖ OBRIGAT√ìRIO',
        'preferencia': 'üí° PREFER√äNCIAS',
        'novo_padrao': 'üÜï NOVOS PADR√ïES',
        'correcao': 'üîß CORRE√á√ïES',
        'formatacao': 'üìù FORMATA√á√ÉO',
        'geral': 'üìã GERAIS'
    }
    
    for category, items in by_category.items():
        if items:
            formatted += f"\n### {category_names.get(category, category.upper())}\n"
            for item in items[-5:]:  # √öltimos 5 de cada categoria
                formatted += f"- {item['rule']}\n"
    
    return formatted

# --- Sistema de Versionamento de Contexto ---
import hashlib
import shutil
from datetime import datetime
import difflib

def load_version_config():
    """Carrega a configura√ß√£o do sistema de versionamento"""
    try:
        with open('memoria/versoes/config_versoes.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar config de vers√µes: {e}")
        return {}

def save_version_config(config):
    """Salva a configura√ß√£o do sistema de versionamento"""
    try:
        with open('memoria/versoes/config_versoes.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"‚ùå Erro ao salvar config de vers√µes: {e}")
        return False

def calculate_content_hash(content):
    """Calcula hash MD5 do conte√∫do para detectar mudan√ßas"""
    return hashlib.md5(content.encode('utf-8')).hexdigest()

def detect_significant_change(old_content, new_content, threshold=0.1):
    """Detecta se houve mudan√ßa significativa no conte√∫do"""
    if not old_content or not new_content:
        return True
        
    # Usar difflib para calcular similaridade
    similarity = difflib.SequenceMatcher(None, old_content, new_content).ratio()
    change_ratio = 1 - similarity
    
    return change_ratio >= threshold

def generate_version_number(current_version, change_type="auto"):
    """Gera novo n√∫mero de vers√£o baseado no tipo de mudan√ßa"""
    try:
        # Parsear vers√£o atual (ex: v1.2.3)
        version_parts = current_version.replace('v', '').split('.')
        major, minor, patch = map(int, version_parts)
        
        if change_type == "major":
            major += 1
            minor = 0
            patch = 0
        elif change_type == "minor":
            minor += 1
            patch = 0
        else:  # patch ou auto
            patch += 1
            
        return f"v{major}.{minor}.{patch}"
    except:
        # Fallback para vers√£o com timestamp se parsing falhar
        timestamp = int(__import__('time').time())
        return f"v1.0.{timestamp}"

def create_version_snapshot(version_number, change_type="auto", description=""):
    """Cria um snapshot completo do sistema atual"""
    try:
        timestamp = datetime.now().isoformat()
        
        # Criar diret√≥rio da vers√£o
        version_dir = f"memoria/versoes/{version_number}"
        os.makedirs(version_dir, exist_ok=True)
        
        # Snapshot de todos os arquivos importantes
        files_to_backup = [
            "memoria/referencias_base.md",
            "memoria/aprendizados_usuario.jsonl",
            "memoria/config_memoria.json",
            "gabaritoestacoes.json"
        ]
        
        # Backup dos contextos otimizados
        for fase in ["fase1", "fase2", "fase3", "fase4"]:
            files_to_backup.append(f"memoria/contexto_otimizado/{fase}_*.md")
        
        # Calcular tamanho total
        total_size = 0
        backed_files = []
        
        for file_pattern in files_to_backup:
            if "*" in file_pattern:
                # Usar glob para padr√µes
                import glob
                matching_files = glob.glob(file_pattern)
                for file_path in matching_files:
                    if os.path.exists(file_path):
                        target_path = os.path.join(version_dir, os.path.basename(file_path))
                        shutil.copy2(file_path, target_path)
                        total_size += os.path.getsize(file_path)
                        backed_files.append(os.path.basename(file_path))
            else:
                if os.path.exists(file_pattern):
                    target_path = os.path.join(version_dir, os.path.basename(file_pattern))
                    shutil.copy2(file_pattern, target_path)
                    total_size += os.path.getsize(file_pattern)
                    backed_files.append(os.path.basename(file_pattern))
        
        # Criar metadados da vers√£o
        version_metadata = {
            "version": version_number,
            "timestamp": timestamp,
            "change_type": change_type,
            "description": description or f"Backup autom√°tico {change_type}",
            "total_size_bytes": total_size,
            "files_count": len(backed_files),
            "files": backed_files,
            "system_state": {
                "hybrid_active": bool(LOCAL_MEMORY_SYSTEM),
                "learnings_count": len(LOCAL_MEMORY_SYSTEM.get('aprendizados', [])),
                "contexts_count": len(LOCAL_MEMORY_SYSTEM.get('contextos', {}))
            }
        }
        
        # Salvar metadados
        metadata_path = os.path.join(version_dir, "metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(version_metadata, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Snapshot criado: {version_number}")
        print(f"üìÇ Arquivos: {len(backed_files)}, Tamanho: {total_size/1024:.1f}KB")
        
        return version_metadata
        
    except Exception as e:
        print(f"‚ùå Erro ao criar snapshot: {e}")
        return None

def initialize_version_system():
    """Inicializa o sistema de versionamento"""
    global VERSION_SYSTEM
    try:
        print("üì¶ Inicializando sistema de versionamento...")
        
        # Carregar configura√ß√£o
        config = load_version_config()
        if not config:
            print("‚ùå Falha ao carregar configura√ß√£o de vers√µes")
            return False
            
        VERSION_SYSTEM = config
        
        # Verificar se √© a primeira execu√ß√£o
        sistema_versoes = VERSION_SYSTEM.get('sistema_versionamento', {})
        historico = sistema_versoes.get('historico_versoes', [])
        
        if not historico:
            print("üÜï Primeira execu√ß√£o - criando vers√£o inicial...")
            metadata = create_version_snapshot("v1.0.0", "major", "Vers√£o inicial do sistema h√≠brido")
            
            if metadata:
                # Atualizar configura√ß√£o
                sistema_versoes['versao_atual'] = "v1.0.0"
                sistema_versoes['historico_versoes'] = [metadata]
                sistema_versoes['metricas']['total_versoes'] = 1
                sistema_versoes['metricas']['ultima_atualizacao'] = metadata['timestamp']
                sistema_versoes['metricas']['tamanho_total_bytes'] = metadata['total_size_bytes']
                
                VERSION_SYSTEM['sistema_versionamento'] = sistema_versoes
                save_version_config(VERSION_SYSTEM)
        
        versao_atual = sistema_versoes.get('versao_atual', 'v1.0.0')
        total_versoes = sistema_versoes.get('metricas', {}).get('total_versoes', 0)
        
        print(f"‚úÖ Sistema de versionamento ativo!")
        print(f"üìå Vers√£o atual: {versao_atual}")
        print(f"üìä Total de vers√µes: {total_versoes}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao inicializar versionamento: {e}")
        return False

def auto_version_on_change(description="Mudan√ßa autom√°tica detectada"):
    """Cria vers√£o automaticamente quando detecta mudan√ßas significativas"""
    try:
        if not VERSION_SYSTEM:
            return False
            
        # Obter conte√∫do atual
        current_content = ""
        for file_path in ["memoria/referencias_base.md", "memoria/aprendizados_usuario.jsonl"]:
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    current_content += f.read()
        
        # Obter vers√£o atual
        sistema_versoes = VERSION_SYSTEM.get('sistema_versionamento', {})
        versao_atual = sistema_versoes.get('versao_atual', 'v1.0.0')
        
        # Verificar se h√° mudan√ßas significativas
        # (Implementa√ß√£o simplificada - na pr√°tica, compararia com √∫ltima vers√£o)
        current_hash = calculate_content_hash(current_content)
        
        # Gerar nova vers√£o
        nova_versao = generate_version_number(versao_atual, "patch")
        metadata = create_version_snapshot(nova_versao, "auto", description)
        
        if metadata:
            # Atualizar sistema
            historico = sistema_versoes.get('historico_versoes', [])
            historico.append(metadata)
            
            # Manter apenas as √∫ltimas N vers√µes
            max_versoes = sistema_versoes.get('configuracao', {}).get('max_versoes', 50)
            if len(historico) > max_versoes:
                historico = historico[-max_versoes:]
            
            # Atualizar m√©tricas
            sistema_versoes['versao_atual'] = nova_versao
            sistema_versoes['historico_versoes'] = historico
            sistema_versoes['metricas']['total_versoes'] = len(historico)
            sistema_versoes['metricas']['ultima_atualizacao'] = metadata['timestamp']
            
            VERSION_SYSTEM['sistema_versionamento'] = sistema_versoes
            save_version_config(VERSION_SYSTEM)
            
            print(f"üîÑ Nova vers√£o criada automaticamente: {nova_versao}")
            return True
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erro no versionamento autom√°tico: {e}")
        return False

def get_version_history(limit=10):
    """Retorna o hist√≥rico de vers√µes"""
    if not VERSION_SYSTEM:
        return []
        
    historico = VERSION_SYSTEM.get('sistema_versionamento', {}).get('historico_versoes', [])
    return historico[-limit:] if historico else []

def rollback_to_version(version_number):
    """Faz rollback para uma vers√£o espec√≠fica"""
    try:
        # Verificar se a vers√£o existe
        version_dir = f"memoria/versoes/{version_number}"
        if not os.path.exists(version_dir):
            return False, f"Vers√£o {version_number} n√£o encontrada"
        
        # Criar backup da vers√£o atual antes do rollback
        versao_atual = VERSION_SYSTEM.get('sistema_versionamento', {}).get('versao_atual', 'v1.0.0')
        backup_version = generate_version_number(versao_atual, "patch")
        create_version_snapshot(backup_version, "backup", f"Backup antes de rollback para {version_number}")
        
        # Restaurar arquivos da vers√£o solicitada
        metadata_path = os.path.join(version_dir, "metadata.json")
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        for file_name in metadata['files']:
            source_path = os.path.join(version_dir, file_name)
            if file_name.startswith('fase'):
                target_path = f"memoria/contexto_otimizado/{file_name}"
            elif file_name == 'gabaritoestacoes.json':
                target_path = file_name
            else:
                target_path = f"memoria/{file_name}"
            
            if os.path.exists(source_path):
                os.makedirs(os.path.dirname(target_path), exist_ok=True)
                shutil.copy2(source_path, target_path)
        
        print(f"‚úÖ Rollback para {version_number} conclu√≠do!")
        return True, f"Sistema restaurado para vers√£o {version_number}"
        
    except Exception as e:
        return False, f"Erro no rollback: {e}"

# --- Fun√ß√µes de Inicializa√ß√£o ---
def initialize_firebase():
    global db, firebase_mock_mode
    try:
        # Preferir arquivo de credenciais local (evita erro de ADC quando n√£o configurado)
        service_account_paths = [
            os.path.join('memoria', 'serviceAccountKey.json'),
            'serviceAccountKey.json'
        ]

        # Se houver vari√°vel de ambiente apontando para um arquivo, tentar us√°-la primeiro
        env_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
        if env_path and os.path.exists(env_path):
            try:
                cred = credentials.Certificate(env_path)
                if not firebase_admin._apps:
                    firebase_admin.initialize_app(cred)
                
                # Teste de conectividade com timeout curto
                import signal
                def timeout_handler(signum, frame):
                    raise TimeoutError("Timeout na inicializa√ß√£o Firebase")
                
                # Configurar timeout apenas no Linux/Unix que suportam SIGALRM
                timeout_supported = hasattr(signal, 'SIGALRM') and os.name != 'nt'
                if timeout_supported:
                    signal.signal(signal.SIGALRM, timeout_handler)  # type: ignore
                    signal.alarm(15)  # type: ignore # 15 segundos timeout
                
                try:
                    db = firestore.client()
                    # Teste r√°pido de conectividade
                    test_collections = list(db.collections())
                    if timeout_supported:
                        signal.alarm(0)  # type: ignore # Cancelar timeout
                    print(f"‚úÖ Firebase Admin SDK inicializado com arquivo apontado por GOOGLE_APPLICATION_CREDENTIALS: {env_path}")
                    return True
                except (TimeoutError, Exception) as timeout_err:
                    if timeout_supported:
                        signal.alarm(0)  # type: ignore
                    print(f"‚ö†Ô∏è Timeout ou erro na conectividade Firebase: {timeout_err}")
                    # Continuar com db = None, mas n√£o falhar completamente
                    db = None
                    firebase_mock_mode = True
                    print("üîÑ Continuando em modo local (Firebase indispon√≠vel)")
                    return False
                    
            except Exception as e_env:
                print(f"‚ö†Ô∏è Falha ao inicializar com GOOGLE_APPLICATION_CREDENTIALS={env_path}: {e_env}")

        # Tentar arquivos locais conhecidos
        for path in service_account_paths:
            if os.path.exists(path):
                try:
                    cred = credentials.Certificate(path)
                    if not firebase_admin._apps:
                        firebase_admin.initialize_app(cred)
                    
                    # Teste de conectividade com timeout
                    try:
                        db = firestore.client()
                        print(f"‚úÖ Firebase Admin SDK inicializado com arquivo local: {path}")
                        return True
                    except Exception as connectivity_err:
                        print(f"‚ö†Ô∏è Firebase inicializado mas sem conectividade: {connectivity_err}")
                        db = None
                        firebase_mock_mode = True
                        return False
                        
                except Exception as e_local:
                    print(f"‚ö†Ô∏è Falha ao inicializar com arquivo local {path}: {e_local}")

        # Por fim, tentar Application Default Credentials (padr√£o GCP)
        try:
            cred = credentials.ApplicationDefault()
            if not firebase_admin._apps:
                firebase_admin.initialize_app(cred, {'projectId': os.getenv('FIREBASE_PROJECT_ID', 'revalida-companion')})
            db = firestore.client()
            print("‚úÖ Firebase Admin SDK inicializado com Application Default Credentials.")
            return True
        except Exception as adc_error:
            print(f"‚ö†Ô∏è Falha com Application Default Credentials: {adc_error}")
            
    except Exception as e_final:
        print(f"‚ö†Ô∏è Erro geral ao inicializar Firebase Admin SDK: {e_final}")
    
    # Se chegou aqui, todas as tentativas falharam
    print(f"üîÑ Ativando modo h√≠brido local (sem sincroniza√ß√£o Firestore)")
    print(f"‚úÖ Sistema local funcionando normalmente!")
    firebase_mock_mode = True
    db = None
    return False

# ====================================
# üìä SISTEMA DE MONITORAMENTO EM TEMPO REAL
# ====================================

def initialize_monitoring_system():
    """Inicializa o sistema de monitoramento em tempo real"""
    global MONITORING_SYSTEM
    
    try:
        config_path = os.path.join("memoria", "monitoring", "config_monitoring.json")
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                MONITORING_SYSTEM.update(config)
        
        # Inicializar estruturas de dados em mem√≥ria
        MONITORING_SYSTEM['metrics'] = {
            'requests_count': 0,
            'errors_count': 0,
            'response_times': deque(maxlen=100),
            'memory_usage': deque(maxlen=100),
            'system_uptime': time.time(),
            'tokens_saved': 0,
            'versions_created': 0,
            'learning_events': 0,
            'search_count': 0
        }
        
        # Lista de eventos de busca (sanitizados) para telemetria ‚Äî manter tamanho limitado
        MONITORING_SYSTEM['search_events'] = deque(maxlen=200)
        
        MONITORING_SYSTEM['alerts'] = []
        MONITORING_SYSTEM['active'] = True
        
        # Iniciar thread de coleta de m√©tricas
        monitoring_thread = threading.Thread(target=collect_system_metrics, daemon=True)
        monitoring_thread.start()
        
        print("üìä Sistema de monitoramento inicializado!")
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao inicializar sistema de monitoramento: {e}")
        MONITORING_SYSTEM['active'] = False
        return False

def collect_system_metrics():
    """Coleta m√©tricas do sistema em tempo real"""
    while MONITORING_SYSTEM.get('active', False):
        try:
            # Coletar m√©tricas do sistema
            memory_percent = psutil.virtual_memory().percent
            cpu_percent = psutil.cpu_percent()
            
            # Armazenar m√©tricas
            MONITORING_SYSTEM['metrics']['memory_usage'].append({
                'timestamp': datetime.now().isoformat(),
                'memory_percent': memory_percent,
                'cpu_percent': cpu_percent
            })
            
            # Verificar alertas
            check_alerts(memory_percent, cpu_percent)
            
            # Aguardar intervalo configurado
            interval = MONITORING_SYSTEM.get('monitoring_system', {}).get('configuracao', {}).get('intervalo_coleta', 30)
            time.sleep(interval)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na coleta de m√©tricas: {e}")
            time.sleep(30)  # Aguardar mais tempo em caso de erro

def check_alerts(memory_percent, cpu_percent):
    """Verifica e gera alertas baseado nos thresholds"""
    alerts_config = MONITORING_SYSTEM.get('monitoring_system', {}).get('alertas_configurados', {})
    
    # Alert de mem√≥ria alta
    memory_threshold = float(alerts_config.get('memoria_alta', {}).get('threshold', '85').rstrip('%'))
    if memory_percent > memory_threshold:
        create_alert('memoria_alta', f'Uso de mem√≥ria: {memory_percent:.1f}%')
    
    # Cleanup de alertas antigos (manter apenas √∫ltimos 50)
    if len(MONITORING_SYSTEM['alerts']) > 50:
        MONITORING_SYSTEM['alerts'] = MONITORING_SYSTEM['alerts'][-50:]

def create_alert(alert_type, message):
    """Cria um novo alerta"""
    alert = {
        'type': alert_type,
        'message': message,
        'timestamp': datetime.now().isoformat(),
        'severity': 'warning'
    }
    
    MONITORING_SYSTEM['alerts'].append(alert)
    print(f"üö® ALERT [{alert_type}]: {message}")

def log_search_event(query: str, hit: dict):
    """
    Registra evento de busca sanitizado na estrutura de monitoramento.
    hit: {'title','snippet','link','query'}
    """
    try:
        if not MONITORING_SYSTEM.get('active'):
            return
        event = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "title": hit.get("title", "")[:200],
            "snippet": hit.get("snippet", "")[:1000],  # j√° sanitizado pelo web_search
            "link": hit.get("link", "")[:500]
        }
        # incrementar m√©tricas simples
        MONITORING_SYSTEM['metrics']['search_count'] = MONITORING_SYSTEM['metrics'].get('search_count', 0) + 1
        MONITORING_SYSTEM['search_events'].append(event)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao logar evento de busca: {e}")

def log_request_metric(endpoint, response_time, status_code):
    """Registra m√©tricas de requisi√ß√£o"""
    if not MONITORING_SYSTEM.get('active'):
        return
        
    MONITORING_SYSTEM['metrics']['requests_count'] += 1
    MONITORING_SYSTEM['metrics']['response_times'].append({
        'endpoint': endpoint,
        'response_time': response_time,
        'status_code': status_code,
        'timestamp': datetime.now().isoformat()
    })
    
    if status_code >= 400:
        MONITORING_SYSTEM['metrics']['errors_count'] += 1
        
    # Verificar alerta de tempo de resposta
    if response_time > 5000:  # 5 segundos
        create_alert('tempo_resposta_alto', f'Endpoint {endpoint}: {response_time}ms')

def log_token_savings(tokens_saved):
    """Registra economia de tokens"""
    if MONITORING_SYSTEM.get('active'):
        MONITORING_SYSTEM['metrics']['tokens_saved'] += tokens_saved

def log_version_created():
    """Registra cria√ß√£o de nova vers√£o"""
    if MONITORING_SYSTEM.get('active'):
        MONITORING_SYSTEM['metrics']['versions_created'] += 1

def log_learning_event():
    """Registra evento de aprendizado"""
    if MONITORING_SYSTEM.get('active'):
        MONITORING_SYSTEM['metrics']['learning_events'] += 1

def get_monitoring_stats():
    """Retorna estat√≠sticas do sistema de monitoramento"""
    if not MONITORING_SYSTEM.get('active'):
        return {"status": "inactive"}
    
    metrics = MONITORING_SYSTEM['metrics']
    uptime_seconds = time.time() - metrics['system_uptime']
    uptime_hours = uptime_seconds / 3600
    
    # Calcular m√©dias
    recent_response_times = list(metrics['response_times'])[-10:]  # √∫ltimas 10 requisi√ß√µes
    avg_response_time = sum(rt['response_time'] for rt in recent_response_times) / len(recent_response_times) if recent_response_times else 0
    
    recent_memory = list(metrics['memory_usage'])[-5:]  # √∫ltimas 5 medi√ß√µes
    avg_memory = sum(m['memory_percent'] for m in recent_memory) / len(recent_memory) if recent_memory else 0
    
    return {
        "status": "active",
        "uptime_hours": round(uptime_hours, 2),
        "total_requests": metrics['requests_count'],
        "total_errors": metrics['errors_count'],
        "error_rate": round((metrics['errors_count'] / max(metrics['requests_count'], 1)) * 100, 2),
        "avg_response_time_ms": round(avg_response_time, 2),
        "avg_memory_percent": round(avg_memory, 1),
        "tokens_saved": metrics['tokens_saved'],
        "versions_created": metrics['versions_created'],
        "learning_events": metrics['learning_events'],
        "recent_alerts": MONITORING_SYSTEM['alerts'][-5:],  # √∫ltimos 5 alertas
        "total_alerts": len(MONITORING_SYSTEM['alerts'])
    }

def load_rules_from_firestore():
    global AGENT_RULES, PARSED_REFERENCIAS, VERSION_SYSTEM
    
    # Tentar carregar sistema h√≠brido primeiro
    if initialize_local_memory_system():
        print("üöÄ Sistema h√≠brido de mem√≥ria local ativo!")
        
        # Inicializar sistema de versionamento
        try:
            initialize_version_system()
            VERSION_SYSTEM['active'] = True
            print("üì¶ Sistema de versionamento ativo!")
            
            # Criar snapshot autom√°tico na inicializa√ß√£o
            auto_version_on_change("Inicializa√ß√£o do sistema h√≠brido")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao inicializar sistema de versionamento: {e}")
            VERSION_SYSTEM['active'] = False
        
        # Inicializar sistema de monitoramento
        try:
            initialize_monitoring_system()
            print("üìä Sistema de monitoramento ativo!")
            
            # Registrar economia de tokens na inicializa√ß√£o
            log_token_savings(28000)  # 82% de 35000 tokens m√©dios
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao inicializar sistema de monitoramento: {e}")
            MONITORING_SYSTEM['active'] = False
        
        # Sistema h√≠brido local est√° ativo - pular Firestore
        print("‚ÑπÔ∏è Sistema h√≠brido local ativo - pulando carregamento Firestore")
        
        # ‚úÖ CORRE√á√ÉO: Popular AGENT_RULES com dados do sistema local
        global AGENT_RULES
        if LOCAL_MEMORY_SYSTEM.get('referencias_base'):
            AGENT_RULES = {
                'referencias_md': LOCAL_MEMORY_SYSTEM.get('referencias_base', ''),
                'gabarito_json': LOCAL_MEMORY_SYSTEM.get('gabarito_template', '{}'),
                'config': LOCAL_MEMORY_SYSTEM.get('config', {}),
                'aprendizados': LOCAL_MEMORY_SYSTEM.get('aprendizados', [])
            }
            print(f"‚úÖ AGENT_RULES populado com {len(AGENT_RULES.get('referencias_md', ''))} caracteres de refer√™ncias")
        
        print("‚úÖ Inicializa√ß√£o completa do sistema h√≠brido!")
        return
    
    # Fallback para sistema antigo se sistema local falhar
    print("üîÑ Usando sistema de mem√≥ria tradicional (Firestore)...")
    if firebase_mock_mode or not db: return
    try:
        print("üß† Carregando regras do Firestore...")
        doc_ref = db.collection('agent_config').document('rules')
        doc = doc_ref.get()
        if doc.exists:
            AGENT_RULES = doc.to_dict() or {}  # Garantir que nunca seja None
            print("‚úÖ Regras carregadas na mem√≥ria com sucesso!")
            
            # Fazer parse do referencias_md para otimiza√ß√£o
            referencias_content = AGENT_RULES.get('referencias_md', '')
            if referencias_content:
                print("üîß Fazendo parse do referencias.md...")
                PARSED_REFERENCIAS = parse_referencias_md(referencias_content)
                if PARSED_REFERENCIAS:
                    print("‚úÖ Referencias.md parsed e otimizado com sucesso!")
                else:
                    print("‚ö†Ô∏è Falha no parsing - usando conte√∫do completo como fallback")
            else:
                print("‚ö†Ô∏è Conte√∫do referencias_md n√£o encontrado no documento")
        else:
            print("‚ùå ERRO: Documento 'rules' n√£o encontrado.")
    except Exception as e:
        print(f"‚ùå ERRO CR√çTICO ao carregar regras do Firestore: {e}")

def configure_gemini_keys():
    global GEMINI_CONFIGS
    # Configura√ß√£o organizada por modelo preferencial
    flash_configs = [
        # GEMINI 2.5 FLASH - PARA FASE 1 (AN√ÅLISE INICIAL)
        (os.getenv("GEMINI_API_KEY_1"), 'gemini-2.5-flash'),
        (os.getenv("GEMINI_API_KEY_2"), 'gemini-2.5-flash'),
        (os.getenv("GEMINI_API_KEY_3"), 'gemini-2.5-flash'),
        (os.getenv("GEMINI_API_KEY_4"), 'gemini-2.5-flash'),
    ]
    
    pro_configs = [
        # GEMINI 2.5 PRO - PARA FASES 2, 3 E 4 (GERA√á√ÉO AVAN√áADA)
        (os.getenv("GEMINI_API_KEY_1"), 'gemini-2.5-pro'),
        (os.getenv("GEMINI_API_KEY_2"), 'gemini-2.5-pro'),
        (os.getenv("GEMINI_API_KEY_3"), 'gemini-2.5-pro'),
        (os.getenv("GEMINI_API_KEY_4"), 'gemini-2.5-pro'),
    ]
    
    # Todas as configura√ß√µes dispon√≠veis (para fallback)
    all_configs = pro_configs + flash_configs + [
        # FALLBACK PARA OUTROS MODELOS 
        (os.getenv("GEMINI_API_KEY_1"), 'gemini-2.5-flash-lite'),
        (os.getenv("GEMINI_API_KEY_2"), 'gemini-2.5-flash-lite'),
        (os.getenv("GEMINI_API_KEY_3"), 'gemini-2.5-flash-lite'),
        (os.getenv("GEMINI_API_KEY_4"), 'gemini-2.5-flash-lite')
    ]
    
    GEMINI_CONFIGS = {
        'flash': [{"key": key, "model_name": model} for key, model in flash_configs if key],
        'pro': [{"key": key, "model_name": model} for key, model in pro_configs if key],
        'all': [{"key": key, "model_name": model} for key, model in all_configs if key]
    }
    
    if not GEMINI_CONFIGS.get('all'):
        print("üî¥ Nenhuma chave de API do Gemini foi encontrada.")
    else:
        flash_count = len(GEMINI_CONFIGS.get('flash', []))
        pro_count = len(GEMINI_CONFIGS.get('pro', []))
        print(f"‚úÖ Configuradas {flash_count} chave(s) Flash e {pro_count} chave(s) Pro do Gemini.")

# --- Gerenciador de Ciclo de Vida ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    if initialize_firebase():
        load_rules_from_firestore()
    configure_gemini_keys()
    yield
    print("Servidor finalizado.")

# --- Aplica√ß√£o FastAPI ---
app = FastAPI(title="Agente de IA", version="1.0.0", lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# Incluir rota RAG (busca por similaridade usando embeddings locais)
try:
    from rag_agent import router as rag_router
    app.include_router(rag_router)
    print("‚úÖ Rota RAG inclu√≠da com sucesso!")
except ImportError as e:
    print(f"‚ö†Ô∏è N√£o foi poss√≠vel incluir rota RAG: erro de importa√ß√£o - {e}")
except Exception as e:
    print(f"‚ö†Ô∏è N√£o foi poss√≠vel incluir rota RAG: {e}")

# --- Middleware de Monitoramento ---
@app.middleware("http")
async def monitoring_middleware(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = (time.time() - start_time) * 1000  # Em milissegundos
    
    # Registrar m√©tricas
    endpoint = request.url.path
    log_request_metric(endpoint, process_time, response.status_code)
    
    # Adicionar header com tempo de resposta
    response.headers["X-Process-Time"] = str(process_time)
    
    return response

# --- Fun√ß√µes de Constru√ß√£o de Prompts (build_prompt_fase_1 atualizada) ---
def build_prompt_fase_1(tema: str, especialidade: str, pdf_content: str | None = None) -> str:
    """Constr√≥i o prompt para a Fase 1, incluindo o conte√∫do do PDF se fornecido."""
    
    pdf_instruction = ""
    if pdf_content:
        pdf_instruction = f"""
**FONTE PRIM√ÅRIA DE CONHECIMENTO (PDF Fornecido):**
---
{pdf_content}
---

**INSTRU√á√ïES ESPEC√çFICAS PARA AN√ÅLISE DO PDF:**
1. **LEIA O √çNDICE**: Identifique se√ß√µes relacionadas ao tema "{tema}"
2. **EXTRAIA APENAS O RELEVANTE**: Foque no que √© essencial para esta√ß√µes m√©dicas sobre "{tema}"
3. **IGNORE CONTE√öDO N√ÉO RELACIONADO**: Pule temas/doen√ßas diferentes do solicitado
4. **ESTRUTURE A INFORMA√á√ÉO**: Organize conforme os t√≥picos solicitados abaixo
"""
    
    return f"""
# FASE 1: AN√ÅLISE E CONTEXTUALIZA√á√ÉO ESPEC√çFICA

**SUA TAREFA PRINCIPAL:**
Criar um resumo cl√≠nico FOCADO ESPECIFICAMENTE no tema "{tema}" em {especialidade}.

**METODOLOGIA:**
1. **Analise a Fonte Prim√°ria (se PDF fornecido):** 
   - Use o PDF como sua PRINCIPAL fonte de verdade para conduta cl√≠nica
   - Leia o √≠ndice e extraia apenas informa√ß√µes sobre "{tema}"
   - Fa√ßa um relat√≥rio preciso focando no essencial para esta√ß√µes m√©dicas
   - IGNORE outros temas/doen√ßas que possam estar no arquivo
   
   **T√≥picos a buscar no PDF:**
   - Conceitos iniciais relevantes ao tema/doen√ßa espec√≠fica
   - T√≥picos e subt√≠tulos referentes ao TEMA CENTRAL "{tema}": 
     * Classifica√ß√£o, fatores de risco, fatores de prote√ß√£o
     * Preven√ß√£o, quadro cl√≠nico, diagn√≥stico, diagn√≥stico diferencial
     * Avalia√ß√£o pr√©-operat√≥ria, estadiamento, tratamento
     * Progn√≥stico, complica√ß√µes
   - Refer√™ncias bibliogr√°ficas espec√≠ficas
   - Considera√ß√µes finais sobre o tema

2. **Pesquise Normativas Complementares:** 
   - "Casos cl√≠nicos reais {tema}"
   - "Diretrizes brasileiras {tema}"
   - "Protocolo {tema} Revalida INEP"
   - "Consenso {tema} sociedade brasileira de {especialidade}"

3. **Sintetize o Conhecimento:** 
   Com base em TODAS as fontes (PDF se existir + conte√∫do web), crie um resumo objetivo utilizando EXATAMENTE esta estrutura:

   * **Contexto Cl√≠nico:**
   * **Anamnese Completa:** (hist√≥ria da doen√ßa atual, antecedentes patol√≥gicos/fisiol√≥gicos, antecedentes familiares, h√°bitos de vida, outros achados relevantes)
   * **Exame F√≠sico:** (altera√ß√µes esperadas nos sinais vitais, exame f√≠sico geral, manobras semiol√≥gicas espec√≠ficas)
   * **Crit√©rios Diagn√≥sticos Principais:** (crit√©rios essenciais para o diagn√≥stico)
   * **Exames Complementares:** 
     - Laboratoriais padr√£o e espec√≠ficos
     - Exames de imagem de rotina e espec√≠ficos
     - Conforme normas e diretrizes
   * **Altera√ß√µes nos Sinais Vitais e Exame F√≠sico:**
   * **Hip√≥teses Diagn√≥sticas:** (s√≠ndrome principal e diferenciais)
   * **Diagn√≥sticos Diferenciais a Descartar:**
   * **Tratamento de Primeira e Segunda Linha:**
   * **Avalia√ß√£o Pr√©-operat√≥ria:** (se aplic√°vel)
   * **Sinais de Alarme/Complica√ß√µes:**
   * **Fatores de Risco:**
   * **Fatores de Prote√ß√£o:**
   * **Estadiamento e Encaminhamentos:** (se aplic√°vel)
   * **Orienta√ß√µes e Seguimento:**
   * **Contraindica√ß√µes e Efeitos Colaterais:**
   * **Notifica√ß√µes Obrigat√≥rias:** (SINAM, CAPS-AD, etc., se aplic√°vel)
   * **Rastreamento e Preven√ß√£o:**

{pdf_instruction}
"""

# (As outras fun√ß√µes de build_prompt permanecem as mesmas)
def build_prompt_fase_2(tema: str, especialidade: str, resumo_clinico: str) -> str:
    """Constr√≥i o prompt da Fase 2 usando sistema h√≠brido de mem√≥ria"""
    
    # Usar sistema h√≠brido se dispon√≠vel
    if LOCAL_MEMORY_SYSTEM:
        print("üöÄ Usando sistema h√≠brido para Fase 2...")
        contexto_otimizado = get_context_for_phase(2)
    else:
        print("üîÑ Fallback para sistema tradicional...")
        # Se√ß√µes espec√≠ficas para Fase 2: 0, 1, 2, 3, 4.1, 4.2, 6, 8
        secoes_fase_2 = [
            'principios_fundamentais',
            'arquitetura_estacoes', 
            'diretrizes_tarefas',
            'tarefas_especialidade',
            'regras_basicas_ator',
            'regras_contextos_ator',
            'tipos_impressos',
            'estruturas_especialidade'
        ]
        
        # Construir contexto otimizado usando apenas se√ß√µes relevantes
        contexto_otimizado = ""
        if PARSED_REFERENCIAS:
            print("üîß Construindo prompt Fase 2 com se√ß√µes otimizadas...")
            for secao in secoes_fase_2:
                if secao in PARSED_REFERENCIAS:
                    contexto_otimizado += f"\n\n--- {secao.upper().replace('_', ' ')} ---\n"
                    contexto_otimizado += PARSED_REFERENCIAS[secao]
            print(f"üìä Fase 2: {len(contexto_otimizado)} caracteres (vs {len(AGENT_RULES.get('referencias_md', '') if AGENT_RULES else '')} originais)")
        else:
            print("‚ö†Ô∏è PARSED_REFERENCIAS n√£o dispon√≠vel, usando conte√∫do completo como fallback")
            contexto_otimizado = AGENT_RULES.get('referencias_md', "") if AGENT_RULES else ""
    
    return f"""# FASE 2: GERA√á√ÉO DE ESTRAT√âGIAS

**CONTEXTO CL√çNICO:**
{resumo_clinico}

**REGRAS DE ARQUITETURA E DIRETRIZES (SE√á√ïES OTIMIZADAS):**
{contexto_otimizado}

**SUA TAREFA:**
Gere 5 propostas estrat√©gicas para uma esta√ß√£o sobre **{tema}** em **{especialidade}**, variando o tipo e o foco."""

def build_prompt_fase_3(request: GenerateFinalStationRequest) -> str:
    """Constr√≥i o prompt da Fase 3 usando se√ß√µes espec√≠ficas do referencias.md + gabarito.json"""
    
    # Usar sistema h√≠brido se dispon√≠vel
    if LOCAL_MEMORY_SYSTEM:
        print("üöÄ Usando sistema h√≠brido para Fase 3...")
        contexto_otimizado = get_context_for_phase(3)
        gabarito_json = get_gabarito_template()
    else:
        print("üîÑ Fallback para sistema tradicional...")
        # Se√ß√µes espec√≠ficas para Fase 3: 0, 1, 2, 3, 4, 5, 6, 7, 8, 10
        secoes_fase_3 = [
            'principios_fundamentais',
            'arquitetura_estacoes',
            'diretrizes_tarefas', 
            'tarefas_especialidade',
            'roteiro_ator_completo',
            'banco_semiologia',
            'tipos_impressos',
            'diretrizes_pep',
            'estruturas_especialidade',
            'regra_aprendida'
        ]
        
        # Construir contexto otimizado usando apenas se√ß√µes relevantes
        contexto_otimizado = ""
        if PARSED_REFERENCIAS:
            print("üîß Construindo prompt Fase 3 com se√ß√µes otimizadas...")
            for secao in secoes_fase_3:
                if secao in PARSED_REFERENCIAS:
                    contexto_otimizado += f"\n\n--- {secao.upper().replace('_', ' ')} ---\n"
                    contexto_otimizado += PARSED_REFERENCIAS[secao]
            print(f"üìä Fase 3: {len(contexto_otimizado)} caracteres (vs {len(AGENT_RULES.get('referencias_md', '') if AGENT_RULES else '')} originais)")
        else:
            print("‚ö†Ô∏è PARSED_REFERENCIAS n√£o dispon√≠vel, usando conte√∫do completo como fallback")
            contexto_otimizado = AGENT_RULES.get('referencias_md', "") if AGENT_RULES else ""
        
        gabarito_json = AGENT_RULES.get('gabarito_json', "{}") if AGENT_RULES else "{}"
    
    return f"""# FASE 3: GERA√á√ÉO DO JSON COMPLETO

**CONTEXTO CL√çNICO:**
{request.resumo_clinico}

**PROPOSTA ESTRAT√âGICA ESCOLHIDA:**
{request.proposta_escolhida}

**REGRAS DE CONTE√öDO E ESTRUTURA (SE√á√ïES OTIMIZADAS):**
{contexto_otimizado}

**MOLDE JSON A SER PREENCHIDO:**
{gabarito_json}

**SUA TAREFA:**
Gere o c√≥digo JSON completo para a esta√ß√£o sobre **{request.tema}** em **{request.especialidade}**, seguindo rigorosamente a proposta, as regras e o molde fornecidos."""

def build_prompt_analise(station_json_str: str, feedback: str | None) -> str:
    """Constr√≥i o prompt da Fase 4 (an√°lise) usando sistema h√≠brido de mem√≥ria"""
    
    # Usar sistema h√≠brido se dispon√≠vel
    if LOCAL_MEMORY_SYSTEM:
        print("üöÄ Usando sistema h√≠brido para Fase 4...")
        contexto_otimizado = get_context_for_phase(4)
    else:
        print("üîÑ Fallback para sistema tradicional...")
        # Se√ß√µes espec√≠ficas para Fase 4: 0, 9, 10
        secoes_fase_4 = [
            'principios_fundamentais',
            'checklist_validacao',
            'regra_aprendida'
        ]
        
        # Construir contexto otimizado usando apenas se√ß√µes relevantes
        contexto_otimizado = ""
        if PARSED_REFERENCIAS:
            print("üîß Construindo prompt Fase 4 (an√°lise) com se√ß√µes otimizadas...")
            for secao in secoes_fase_4:
                if secao in PARSED_REFERENCIAS:
                    contexto_otimizado += f"\n\n--- {secao.upper().replace('_', ' ')} ---\n"
                    contexto_otimizado += PARSED_REFERENCIAS[secao]
            print(f"üìä Fase 4: {len(contexto_otimizado)} caracteres (vs {len(AGENT_RULES.get('referencias_md', '') if AGENT_RULES else '')} originais)")
        else:
            print("‚ö†Ô∏è PARSED_REFERENCIAS n√£o dispon√≠vel, usando conte√∫do completo como fallback")
            contexto_otimizado = AGENT_RULES.get('referencias_md', "Regras de cria√ß√£o n√£o carregadas.") if AGENT_RULES else "Regras de cria√ß√£o n√£o carregadas."
    
    feedback_section = f"\n\n**DIRETRIZES ADICIONAIS DO USU√ÅRIO:**\n{feedback}\n" if feedback else ""
    
    return f"""# AN√ÅLISE DE ESTA√á√ÉO CL√çNICA

**PERSONA:** Avaliador s√™nior do INEP.

**REGRAS DE AVALIA√á√ÉO (SE√á√ïES OTIMIZADAS):**
{contexto_otimizado}{feedback_section}

**TAREFA:**
Analise o JSON da esta√ß√£o abaixo e forne√ßa um feedback em markdown com: Pontos Fortes, Pontos de Melhoria e Sugest√£o de A√ß√£o.

**JSON PARA AN√ÅLISE:**
```json
{station_json_str}
```"""

def build_prompt_apply_audit(station_json_str: str, analysis_result: str) -> str:
    return f"""# APLICAR MUDAN√áAS DE AUDITORIA\n\n**PERSONA:** Desenvolvedor de conte√∫do m√©dico experiente.\n\n**TAREFA:**\nVoc√™ receber√° um JSON de uma esta√ß√£o cl√≠nica e o resultado de uma auditoria. Sua √∫nica tarefa √© retornar um NOVO JSON que incorpore as 'Sugest√µes de A√ß√£o' da auditoria. N√ÉO adicione coment√°rios, explica√ß√µes ou use markdown. A sa√≠da deve ser apenas o c√≥digo JSON modificado.\n\n**JSON ORIGINAL:**\n```json\n{station_json_str}\n```\n\n**RESULTADO DA AUDITORIA A SER APLICADO:**\n```markdown\n{analysis_result}\n```\n\n**NOVO JSON (APENAS O C√ìDIGO):**"""

# --- Fun√ß√£o Central de Chamada √† API (modificada para suportar modelos espec√≠ficos) ---
async def call_gemini_api(prompt: str, preferred_model: str = 'pro'):
    """
    Chama a API do Gemini com prefer√™ncia de modelo.
    
    Args:
        prompt: O texto do prompt a ser enviado
        preferred_model: 'flash' para Gemini 2.5 Flash, 'pro' para Gemini 2.5 Pro
    """
    if not GEMINI_CONFIGS or not GEMINI_CONFIGS.get('all'): 
        raise HTTPException(status_code=503, detail="Nenhuma chave de API do Gemini est√° configurada.")
    
    # Determina a ordem de tentativa baseada na prefer√™ncia
    if preferred_model == 'flash':
        configs_to_try = GEMINI_CONFIGS.get('flash', []) + GEMINI_CONFIGS.get('pro', [])
        print(f"üöÄ Usando Gemini 2.5 Flash para processamento r√°pido...")
    else:  # 'pro' ou qualquer outro valor
        configs_to_try = GEMINI_CONFIGS.get('pro', []) + GEMINI_CONFIGS.get('flash', [])
        print(f"üß† Usando Gemini 2.5 Pro para processamento avan√ßado...")
    
    # Se n√£o tiver configura√ß√µes espec√≠ficas, usa todas dispon√≠veis
    if not configs_to_try:
        configs_to_try = GEMINI_CONFIGS.get('all', [])
    
    for i, config in enumerate(configs_to_try):
        try:
            print(f"‚û°Ô∏è  Tentando API Key #{i+1} com modelo {config['model_name']}...")
            genai.configure(api_key=config['key'])  # type: ignore
            model = genai.GenerativeModel(config['model_name'])  # type: ignore
            response = await model.generate_content_async(prompt)
            
            # Verifica se a resposta tem candidatos v√°lidos
            if not response.candidates:
                print(f"‚ö†Ô∏è  {config['model_name']} (API Key #{i+1}): Nenhum candidato retornado.")
                if i == len(configs_to_try) - 1:
                    raise HTTPException(status_code=500, detail="Nenhum candidato v√°lido retornado pelo modelo.")
                continue
            
            # Verifica o finish_reason do primeiro candidato
            candidate = response.candidates[0]
            if not candidate.content or not candidate.content.parts:
                finish_reason_code = candidate.finish_reason
                finish_reason_name = FINISH_REASON_NAMES.get(finish_reason_code, f"UNKNOWN_{finish_reason_code}")
                
                print(f"‚ö†Ô∏è  {config['model_name']} (API Key #{i+1}): Resposta sem conte√∫do v√°lido.")
                print(f"üîç finish_reason: {finish_reason_code} ({finish_reason_name})")
                
                # Log detalhado baseado no finish_reason
                if finish_reason_code == 1:  # STOP
                    error_msg = "Modelo parou naturalmente mas sem conte√∫do v√°lido - poss√≠vel prompt vazio ou muito curto"
                elif finish_reason_code == 2:  # MAX_TOKENS
                    error_msg = "Limite de tokens atingido - prompt muito longo ou resposta truncada"
                elif finish_reason_code == 3:  # SAFETY
                    error_msg = "Conte√∫do bloqueado por filtros de seguran√ßa - prompt pode conter conte√∫do sens√≠vel"
                elif finish_reason_code == 4:  # RECITATION
                    error_msg = "Conte√∫do bloqueado por recita√ß√£o - poss√≠vel viola√ß√£o de direitos autorais"
                elif finish_reason_code == 5:  # LANGUAGE
                    error_msg = "Idioma n√£o suportado pelo modelo"
                elif finish_reason_code == 7:  # BLOCKLIST
                    error_msg = "Prompt cont√©m termos da lista de bloqueio"
                elif finish_reason_code == 8:  # PROHIBITED_CONTENT
                    error_msg = "Conte√∫do proibido detectado no prompt"
                else:
                    error_msg = f"{finish_reason_name} - verifique o prompt e tente novamente"
                
                print(f"ÔøΩ Sugest√£o: {error_msg}")
                
                if i == len(configs_to_try) - 1:
                    raise HTTPException(status_code=500, detail=f"Erro na API do Gemini: {error_msg}")
                continue
            
            print(f"‚úÖ Sucesso com {config['model_name']} usando API Key #{i+1}.")
            return response.text
        except google_exceptions.ResourceExhausted:
            print(f"‚ö†Ô∏è  API Key #{i+1} ({config['model_name']}) atingiu o limite de cota.")
            if i == len(configs_to_try) - 1: 
                raise HTTPException(status_code=429, detail="Todas as chaves de API atingiram o limite de cota.")
        except Exception as e:
            print(f"‚ùå Erro com {config['model_name']} (API Key #{i+1}): {e}")
            if i == len(configs_to_try) - 1:
                raise HTTPException(status_code=500, detail=f"Erro na API do Gemini: {e}")
            continue
    
    raise HTTPException(status_code=503, detail="Falha ao processar com todas as chaves.")

# --- Endpoints da API ---
@app.get("/health", tags=["Status"])
def health_check():
    flash_count = len(GEMINI_CONFIGS.get('flash', []))
    pro_count = len(GEMINI_CONFIGS.get('pro', []))
    total_count = len(GEMINI_CONFIGS.get('all', []))
    
    return {
        "status": "ok", 
        "total_keys_loaded": total_count,
        "flash_keys": flash_count,
        "pro_keys": pro_count,
        "models_configured": {
            "fase_1": "gemini-2.5-flash",
            "fases_2_3_4": "gemini-2.5-pro"
        }
    }

@app.get("/api/test-gemini", tags=["Status"])
async def test_gemini():
    """Testa se os modelos Gemini est√£o funcionando"""
    if not GEMINI_CONFIGS or not GEMINI_CONFIGS.get('all'):
        raise HTTPException(status_code=503, detail="Nenhuma chave configurada")
    
    try:
        # Testa primeiro com Flash (usado na Fase 1)
        if GEMINI_CONFIGS.get('flash'):
            config = GEMINI_CONFIGS['flash'][0]
            genai.configure(api_key=config['key'])  # type: ignore
            model = genai.GenerativeModel(config['model_name'])  # type: ignore
            response = await model.generate_content_async("Responda apenas: 'Gemini Flash funcionando!'")
            
            # Verifica se a resposta √© v√°lida antes de acessar response.text
            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                return {
                    "status": "success",
                    "flash_model": config['model_name'],
                    "pro_models_available": len(GEMINI_CONFIGS.get('pro', [])),
                    "flash_models_available": len(GEMINI_CONFIGS.get('flash', [])),
                    "response": response.text,
                    "message": "Gemini configurado corretamente - Flash para Fase 1, Pro para Fases 2-4!"
                }
            else:
                candidate = response.candidates[0] if response.candidates else None
                finish_reason_code = candidate.finish_reason if candidate else -1
                finish_reason_name = FINISH_REASON_NAMES.get(finish_reason_code, f"UNKNOWN_{finish_reason_code}")
                return {
                    "status": "warning",
                    "flash_model": config['model_name'],
                    "finish_reason_code": finish_reason_code,
                    "finish_reason_name": finish_reason_name,
                    "message": f"Flash respondeu mas sem conte√∫do v√°lido ({finish_reason_name})"
                }
        else:
            # Fallback para Pro se Flash n√£o estiver dispon√≠vel
            config = GEMINI_CONFIGS.get('pro', [{}])[0] if GEMINI_CONFIGS.get('pro') else GEMINI_CONFIGS.get('all', [{}])[0]
            genai.configure(api_key=config['key'])  # type: ignore
            model = genai.GenerativeModel(config['model_name'])  # type: ignore
            response = await model.generate_content_async("Responda apenas: 'Gemini funcionando!'")
            
            # Verifica se a resposta √© v√°lida antes de acessar response.text
            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                return {
                    "status": "success",
                    "model_used": config['model_name'],
                    "response": response.text,
                    "message": "Gemini funcionando, mas sem Flash dispon√≠vel"
                }
            else:
                candidate = response.candidates[0] if response.candidates else None
                finish_reason_code = candidate.finish_reason if candidate else -1
                finish_reason_name = FINISH_REASON_NAMES.get(finish_reason_code, f"UNKNOWN_{finish_reason_code}")
                return {
                    "status": "warning",
                    "model_used": config['model_name'],
                    "finish_reason_code": finish_reason_code,
                    "finish_reason_name": finish_reason_name,
                    "message": f"Modelo respondeu mas sem conte√∫do v√°lido ({finish_reason_name})"
                }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "message": "Erro ao testar Gemini - verifique as chaves de API"
        }

@app.get("/api/gemini-diagnostic", tags=["Status"])
async def gemini_diagnostic():
    """Diagn√≥stico detalhado da API Gemini com an√°lise de finish_reason"""
    if not GEMINI_CONFIGS or not GEMINI_CONFIGS.get('all'):
        raise HTTPException(status_code=503, detail="Nenhuma chave configurada")
    
    diagnostic_results = []
    
    # Testa diferentes prompts para verificar comportamentos
    test_prompts = [
        {"name": "Prompt Normal", "text": "Diga apenas: OK"},
        {"name": "Prompt Vazio", "text": ""},
        {"name": "Prompt Muito Longo", "text": "Explique detalhadamente " + "todas as " * 1000 + "nuances da medicina."},
    ]
    
    for prompt_test in test_prompts:
        for model_type in ['flash', 'pro']:
            if not GEMINI_CONFIGS.get(model_type):
                continue
                
            config = GEMINI_CONFIGS[model_type][0]
            try:
                genai.configure(api_key=config['key'])  # type: ignore
                model = genai.GenerativeModel(config['model_name'])  # type: ignore
                response = await model.generate_content_async(prompt_test["text"])
                
                # An√°lise detalhada da resposta
                result = {
                    "prompt_name": prompt_test["name"],
                    "model": config['model_name'],
                    "has_candidates": bool(response.candidates),
                    "candidates_count": len(response.candidates) if response.candidates else 0
                }
                
                if response.candidates:
                    candidate = response.candidates[0]
                    finish_reason_code = candidate.finish_reason
                    finish_reason_name = FINISH_REASON_NAMES.get(finish_reason_code, f"UNKNOWN_{finish_reason_code}")
                    
                    result.update({
                        "finish_reason_code": finish_reason_code,
                        "finish_reason_name": finish_reason_name,
                        "has_content": bool(candidate.content),
                        "has_parts": bool(candidate.content and candidate.content.parts),
                        "can_access_text": False,
                        "text_preview": None,
                        "error_accessing_text": None
                    })
                    
                    # Tenta acessar response.text de forma segura
                    try:
                        if candidate.content and candidate.content.parts:
                            text_content = response.text
                            result.update({
                                "can_access_text": True,
                                "text_preview": text_content[:100] + "..." if len(text_content) > 100 else text_content
                            })
                        else:
                            result["error_accessing_text"] = "Candidato sem conte√∫do ou partes v√°lidas"
                    except Exception as text_error:
                        result.update({
                            "can_access_text": False,
                            "error_accessing_text": str(text_error)
                        })
                
                diagnostic_results.append(result)
                
            except Exception as e:
                diagnostic_results.append({
                    "prompt_name": prompt_test["name"],
                    "model": config['model_name'],
                    "error": str(e)
                })
    
    return {
        "status": "completed",
        "total_tests": len(diagnostic_results),
        "finish_reason_codes_reference": FINISH_REASON_NAMES,
        "results": diagnostic_results
    }

@app.post("/api/agent/start-creation", tags=["Agente - Gera√ß√£o"])
async def start_creation_process(
    tema: str = Form(...),
    especialidade: str = Form(...),
    pdf_reference: UploadFile = File(None), # O arquivo √© opcional
    enable_web_search: str = Form("0")      # Recebe '1' ou '0' do frontend
):
    """
    Orquestra as Fases 1 e 2, agora aceitando um PDF de refer√™ncia opcional.
    O par√¢metro enable_web_search controla se a busca web ser√° executada (valor '1' habilita).
    """
    if not AGENT_RULES:
        raise HTTPException(status_code=503, detail="Regras do agente n√£o carregadas.")
    
    pdf_content_str = None
    if pdf_reference:
        try:
            print(f"üìÑ Processando PDF: {pdf_reference.filename}")
            
            # Ler os bytes do arquivo PDF
            pdf_content_bytes = await pdf_reference.read()
            
            # Extrair texto estruturado do PDF usando PyMuPDF
            pdf_content_str = extract_pdf_content_structured(pdf_content_bytes, tema)
            
            print(f"‚úÖ PDF processado com sucesso! Extra√≠do texto de {pdf_reference.filename}")
            print(f"ÔøΩ Tamanho do conte√∫do extra√≠do: {len(pdf_content_str)} caracteres")
            
        except Exception as e:
            print(f"‚ùå Erro ao processar PDF: {e}")
            raise HTTPException(status_code=400, detail=f"N√£o foi poss√≠vel processar o arquivo PDF: {e}")
    
    # --- BUSCA WEB EM TEMPO REAL (opcional) ---
    web_search_summary = ""
    hits = []
    try:
        # Interpretar flag enviada pelo frontend
        enabled_flag = str(enable_web_search).lower() in ("1", "true", "yes")
        serp_key = os.getenv("SERPAPI_KEY")
        if enabled_flag and serp_key:
            queries = [
                f"diretrizes atualizadas {tema} {especialidade} Brasil",
                f"protocolo cl√≠nico {tema} Revalida",
                f"consenso {tema} sociedade brasileira de {especialidade}"
            ]
            for q in queries:
                try:
                    # search_web √© s√≠ncrono ‚Äî executar em thread para n√£o bloquear o loop async
                    res = await asyncio.to_thread(search_web, q, 3, True)
                    for r in res:
                        hits.append({"query": q, **r})
                except Exception as we:
                    print(f"‚ö†Ô∏è Falha na busca web para query '{q}': {we}")
        else:
            if not enabled_flag:
                print("‚ÑπÔ∏è Busca web desabilitada por flag do frontend.")
            else:
                print("‚ö†Ô∏è SERPAPI_KEY n√£o configurado ‚Äî pulando buscas web.")
            hits = []
    except Exception as e:
        print(f"‚ö†Ô∏è M√≥dulo de busca web n√£o dispon√≠vel: {e}")
        hits = []
    
    if hits:
        web_lines = []
        for h in hits:
            title = h.get("title", "").strip()
            snippet = h.get("snippet", "").strip()
            link = h.get("link", "").strip()
            web_lines.append(f"- {title}: {snippet} ({link})")
        web_search_summary = "\n".join(web_lines)

        # Registrar telemetria: eventos de busca sanitizados (n√£o incluir PII adicional)
        try:
            for h in hits:
                # cada hit j√° cont√©m 'query' adicionado anteriormente
                log_search_event(h.get("query", ""), h)
        except Exception as te:
            print(f"‚ö†Ô∏è Erro ao registrar telemetria de busca: {te}")
    
    # Combinar contexto do PDF (se houver) com resultados da busca web
    if pdf_content_str and web_search_summary:
        combined_context = f"{pdf_content_str}\n\nRESULTADOS DA BUSCA EM TEMPO REAL:\n{web_search_summary}"
    elif web_search_summary and not pdf_content_str:
        combined_context = f"RESULTADOS DA BUSCA EM TEMPO REAL:\n{web_search_summary}"
    else:
        combined_context = pdf_content_str
    
    # --- FASE 1 (USAR GEMINI 2.5 FLASH) ---
    print(f"üöÄ Iniciando Fase 1 (Flash) para Tema: {tema}")
    prompt_fase_1 = build_prompt_fase_1(tema, especialidade, combined_context)
    resumo_clinico = await call_gemini_api(prompt_fase_1, preferred_model='flash')
    print("‚úÖ Fase 1 (Resumo Cl√≠nico com Flash) conclu√≠da.")

    # --- FASE 2 (USAR GEMINI 2.5 PRO) ---
    print("üß† Iniciando Fase 2 (Pro) para gerar propostas...")
    prompt_fase_2 = build_prompt_fase_2(tema, especialidade, resumo_clinico)
    propostas = await call_gemini_api(prompt_fase_2, preferred_model='pro')
    print("‚úÖ Fase 2 (Propostas com Pro) conclu√≠da.")

    return {"resumo_clinico": resumo_clinico, "propostas": propostas}

# ## ENDPOINT MODIFICADO ##
@app.post("/api/agent/generate-final-station", tags=["Agente - Gera√ß√£o"])
async def generate_and_save_final_station(request: GenerateFinalStationRequest):
    """
    Orquestra a Fase 3, gerando o JSON final, SALVANDO no Firestore
    e retornando o ID e os dados da nova esta√ß√£o.
    """
    if not AGENT_RULES or not db:
        raise HTTPException(status_code=503, detail="Regras ou conex√£o com Firestore n√£o dispon√≠veis.")
    
    # 1. Gerar a Esta√ß√£o (USAR GEMINI 2.5 PRO)
    print("ÔøΩ Gerando o conte√∫do da esta√ß√£o com o Gemini 2.5 Pro...")
    prompt_fase_3 = build_prompt_fase_3(request)
    json_output_str = await call_gemini_api(prompt_fase_3, preferred_model='pro')
    
    try:
        if json_output_str.strip().startswith("```json"):
            json_output_str = json_output_str.strip()[7:-3]
        json_output = json.loads(json_output_str)
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="A IA gerou uma resposta em formato JSON inv√°lido.")

    # 2. Salvar a Esta√ß√£o
    try:
        print(f"üíæ Salvando a nova esta√ß√£o na cole√ß√£o 'estacoes_clinicas'...")
        # O m√©todo .add() cria um documento com um ID gerado automaticamente
        update_time, doc_ref = db.collection('estacoes_clinicas').add(json_output)
        new_station_id = doc_ref.id
        print(f"‚úÖ Esta√ß√£o salva com sucesso! ID: {new_station_id}")
    except Exception as e:
        print(f"üö® Erro ao salvar no Firestore: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao salvar a esta√ß√£o no Firestore: {e}")

    # 3. Retornar o resultado
    return {
        "status": "success",
        "message": "Esta√ß√£o gerada e salva com sucesso!",
        "station_id": new_station_id,
        "station_data": json_output
    }


@app.post("/api/agent/analyze-station", tags=["Agente - An√°lise"])
async def analyze_station(request: AnalyzeStationRequest):
    if not AGENT_RULES or not db: raise HTTPException(status_code=503, detail="Regras ou conex√£o com Firestore n√£o dispon√≠veis.")
    try:
        collection_name = 'estacoes_clinicas' # Hardcoded para simplicidade
        print(f"üîé Buscando esta√ß√£o: {collection_name}/{request.station_id}")
        station_ref = db.collection(collection_name).document(request.station_id)
        station_doc = station_ref.get()
        if not station_doc.exists:
            raise HTTPException(status_code=404, detail="Esta√ß√£o n√£o encontrada.")
        
        station_json_str = json.dumps(station_doc.to_dict(), indent=2, ensure_ascii=False)
        analysis_prompt = build_prompt_analise(station_json_str, request.feedback)
        analysis_result = await call_gemini_api(analysis_prompt, preferred_model='flash')
        return {"station_id": request.station_id, "analysis": analysis_result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao analisar esta√ß√£o: {e}")

@app.post("/api/agent/apply-audit", tags=["Agente - An√°lise"])
async def apply_audit(request: ApplyAuditRequest):
    if not db: raise HTTPException(status_code=503, detail="Conex√£o com Firestore n√£o dispon√≠vel.")
    try:
        collection_name = 'estacoes_clinicas'
        station_id = request.station_id
        print(f"üõ†Ô∏è Aplicando auditoria na esta√ß√£o: {collection_name}/{station_id}")

        # 1. Buscar o documento original
        station_ref = db.collection(collection_name).document(station_id)
        station_doc = station_ref.get()
        if not station_doc.exists:
            raise HTTPException(status_code=404, detail="Esta√ß√£o n√£o encontrada para aplicar mudan√ßas.")
        
        original_station_json = json.dumps(station_doc.to_dict(), indent=2, ensure_ascii=False)

        # 2. Chamar a IA para obter o JSON modificado (USAR GEMINI 2.5 PRO)
        prompt = build_prompt_apply_audit(original_station_json, request.analysis_result)
        updated_json_str = await call_gemini_api(prompt, preferred_model='flash')

        # 3. Validar e atualizar o documento
        try:
            if updated_json_str.strip().startswith("```json"):
                updated_json_str = updated_json_str.strip()[7:-3]
            updated_station_data = json.loads(updated_json_str)
        except json.JSONDecodeError:
            raise HTTPException(status_code=500, detail="A IA gerou um JSON modificado inv√°lido.")

        station_ref.set(updated_station_data) # Usar .set() para sobrescrever o documento
        print(f"‚úÖ Mudan√ßas da auditoria aplicadas com sucesso em {station_id}")

        return {
            "status": "success",
            "message": "Mudan√ßas da auditoria aplicadas com sucesso!",
            "station_id": station_id,
            "updated_station_data": updated_station_data
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao aplicar mudan√ßas da auditoria: {e}")


@app.get("/api/agent/get-rules", tags=["Agente - Mem√≥ria"])
def get_rules():
    if not AGENT_RULES: raise HTTPException(status_code=404, detail="Regras n√£o carregadas.")
    return {"status": "success"}

@app.post("/api/agent/update-rules", tags=["Agente - Mem√≥ria"])
async def update_rules(request: Request):
    """Endpoint para atualizar regras usando o sistema h√≠brido de aprendizado"""
    try:
        data = await request.json()
        feedback = data.get("feedback")
        context = data.get("context", "Feedback do usu√°rio via interface")
        category = data.get("category")
        
        if not feedback:
            raise HTTPException(status_code=400, detail="Feedback √© obrigat√≥rio")
        
        # Tentar salvar no sistema h√≠brido primeiro
        local_success = save_learning(feedback, context, category)
        
        # Fallback para Firestore se sistema local falhar ou se n√£o estiver em modo mock
        if not firebase_mock_mode and db:
            try:
                doc_ref = db.collection('agent_config').document('rules')
                current_doc = doc_ref.get()
                
                if current_doc.exists:
                    current_md = (current_doc.to_dict() or {}).get('referencias_md', '')
                    new_rule_md = f"\n\n---\n\n## REGRA APRENDIDA (Feedback do Usu√°rio):\n\n- {feedback}\n"
                    doc_ref.update({'referencias_md': current_md + new_rule_md})
                    print("‚úÖ Backup salvo no Firestore tamb√©m")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao salvar backup no Firestore: {e}")
        
        # Recarregar sistema se necess√°rio
        if local_success and LOCAL_MEMORY_SYSTEM:
            # Recarregar aprendizados na mem√≥ria
            try:
                with open('memoria/aprendizados_usuario.jsonl', 'r', encoding='utf-8') as f:
                    LOCAL_MEMORY_SYSTEM['aprendizados'] = json.load(f)
            except:
                pass
        
        message = "‚úÖ Aprendizado salvo no sistema h√≠brido!" if local_success else "‚úÖ Aprendizado salvo no Firestore!"
        
        return {
            "status": "success", 
            "message": message,
            "system_used": "hibrido" if local_success else "firestore",
            "category": categorize_learning(feedback, context)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao atualizar regras: {e}")

# Novo endpoint para gerenciar aprendizados
@app.get("/api/agent/learnings", tags=["Agente - Mem√≥ria"])
def get_learnings(limit: int = 20):
    """Retorna os aprendizados recentes"""
    try:
        learnings = get_recent_learnings(limit)
        return {
            "status": "success",
            "learnings": learnings,
            "total": len(learnings),
            "system": "hibrido" if LOCAL_MEMORY_SYSTEM else "firestore"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao buscar aprendizados: {e}")

@app.post("/api/agent/add-learning", tags=["Agente - Mem√≥ria"])
async def add_learning(data: UpdateRulesRequest):
    """Adiciona um novo aprendizado de forma estruturada"""
    try:
        success = save_learning(data.new_rule, data.context, data.category)
        
        if success:
            # Registrar evento de aprendizado
            log_learning_event()
            
            return {
                "status": "success",
                "message": "Aprendizado adicionado com sucesso!",
                "category": data.category or categorize_learning(data.new_rule, data.context)
            }
        else:
            raise HTTPException(status_code=500, detail="Falha ao salvar aprendizado")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao adicionar aprendizado: {e}")

# ====================================
# üì¶ ENDPOINTS DO SISTEMA DE VERSIONAMENTO
# ====================================

@app.get("/api/agent/versions", tags=["Agente - Versionamento"])
def get_versions():
    """Lista todas as vers√µes dispon√≠veis do sistema"""
    try:
        if not VERSION_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de versionamento n√£o est√° ativo")
            
        config_path = os.path.join(VERSION_SYSTEM['base_path'], 'config_versoes.json')
        if not os.path.exists(config_path):
            return {"versions": [], "current_version": None}
            
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        return {
            "status": "success",
            "versions": config.get('versions', []),
            "current_version": config.get('current_version'),
            "total_versions": len(config.get('versions', []))
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao listar vers√µes: {e}")

@app.post("/api/agent/create-version", tags=["Agente - Versionamento"])
def create_manual_version(request: dict):
    """Cria uma vers√£o manual do sistema"""
    try:
        if not VERSION_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de versionamento n√£o est√° ativo")
            
        version_type = request.get('type', 'manual')
        description = request.get('description', 'Vers√£o criada manualmente')
        
        version_info = create_version_snapshot(version_type, description)
        
        if version_info:
            # Registrar cria√ß√£o de vers√£o
            log_version_created()
            
            return {
                "status": "success",
                "version_created": version_info,
                "message": f"Vers√£o {version_info['id']} criada com sucesso"
            }
        else:
            raise HTTPException(status_code=500, detail="Falha ao criar vers√£o")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao criar vers√£o: {e}")

@app.post("/api/agent/rollback-version", tags=["Agente - Versionamento"])
def rollback_version(request: dict):
    """Restaura o sistema para uma vers√£o espec√≠fica"""
    try:
        if not VERSION_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de versionamento n√£o est√° ativo")
            
        version_id = request.get('version_id')
        if not version_id:
            raise HTTPException(status_code=400, detail="ID da vers√£o √© obrigat√≥rio")
            
        # Criar backup da vers√£o atual antes do rollback
        current_backup = create_version_snapshot("pre_rollback", f"Backup antes do rollback para {version_id}")
        
        success = rollback_to_version(version_id)
        
        if success:
            return {
                "status": "success",
                "rolled_back_to": version_id,
                "backup_created": current_backup['id'] if current_backup else None,
                "message": f"Sistema restaurado para vers√£o {version_id}"
            }
        else:
            raise HTTPException(status_code=500, detail="Falha ao fazer rollback")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao fazer rollback: {e}")

@app.get("/api/agent/version-details/{version_id}", tags=["Agente - Versionamento"])
def get_version_details(version_id: str):
    """Obt√©m detalhes de uma vers√£o espec√≠fica"""
    try:
        if not VERSION_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de versionamento n√£o est√° ativo")
            
        config_path = os.path.join(VERSION_SYSTEM['base_path'], 'config_versoes.json')
        if not os.path.exists(config_path):
            raise HTTPException(status_code=404, detail="Configura√ß√£o de vers√µes n√£o encontrada")
            
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        version_details = None
        for version in config.get('versions', []):
            if version['id'] == version_id:
                version_details = version
                break
                
        if not version_details:
            raise HTTPException(status_code=404, detail=f"Vers√£o {version_id} n√£o encontrada")
            
        # Tentar carregar arquivos da vers√£o se existirem
        version_path = os.path.join(VERSION_SYSTEM['versions_path'], version_id)
        files_info = {}
        
        if os.path.exists(version_path):
            for filename in os.listdir(version_path):
                file_path = os.path.join(version_path, filename)
                if os.path.isfile(file_path):
                    files_info[filename] = {
                        "size": os.path.getsize(file_path),
                        "modified": os.path.getmtime(file_path)
                    }
        
        version_details['files'] = files_info
        
        return {
            "status": "success",
            "version": version_details
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao obter detalhes da vers√£o: {e}")

@app.delete("/api/agent/delete-version/{version_id}", tags=["Agente - Versionamento"])
def delete_version(version_id: str):
    """Remove uma vers√£o espec√≠fica (exceto a atual)"""
    try:
        if not VERSION_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de versionamento n√£o est√° ativo")
            
        config_path = os.path.join(VERSION_SYSTEM['base_path'], 'config_versoes.json')
        if not os.path.exists(config_path):
            raise HTTPException(status_code=404, detail="Configura√ß√£o de vers√µes n√£o encontrada")
            
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        # Verificar se n√£o √© a vers√£o atual
        if config.get('current_version') == version_id:
            raise HTTPException(status_code=400, detail="N√£o √© poss√≠vel deletar a vers√£o atual")
            
        # Encontrar e remover a vers√£o
        versions = config.get('versions', [])
        version_found = False
        updated_versions = []
        
        for version in versions:
            if version['id'] == version_id:
                version_found = True
                # Remover arquivos da vers√£o
                version_path = os.path.join(VERSION_SYSTEM['versions_path'], version_id)
                if os.path.exists(version_path):
                    import shutil
                    shutil.rmtree(version_path)
            else:
                updated_versions.append(version)
                
        if not version_found:
            raise HTTPException(status_code=404, detail=f"Vers√£o {version_id} n√£o encontrada")
            
        # Atualizar configura√ß√£o
        config['versions'] = updated_versions
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
            
        return {
            "status": "success",
            "message": f"Vers√£o {version_id} removida com sucesso",
            "remaining_versions": len(updated_versions)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao deletar vers√£o: {e}")

# ====================================
# üìä ENDPOINTS DO SISTEMA DE MONITORAMENTO
# ====================================

@app.get("/api/agent/monitoring", tags=["Agente - Monitoramento"])
def get_monitoring_dashboard():
    """Retorna dados completos do dashboard de monitoramento"""
    try:
        if not MONITORING_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de monitoramento n√£o est√° ativo")
            
        stats = get_monitoring_stats()
        
        # Adicionar dados espec√≠ficos do dashboard
        dashboard_data = {
            **stats,
            "hybrid_system_status": {
                "active": bool(LOCAL_MEMORY_SYSTEM),
                "token_reduction_percent": 82,
                "files_loaded": len(LOCAL_MEMORY_SYSTEM.get('contextos', {})) + 
                              (1 if LOCAL_MEMORY_SYSTEM.get('referencias_base') else 0) +
                              (1 if LOCAL_MEMORY_SYSTEM.get('gabarito_template') else 0)
            },
            "version_system_status": {
                "active": VERSION_SYSTEM.get('active', False),
                "total_versions": len(VERSION_SYSTEM.get('sistema_versionamento', {}).get('historico_versoes', [])),
                "current_version": VERSION_SYSTEM.get('sistema_versionamento', {}).get('versao_atual', 'N/A')
            },
            "learning_system_status": {
                "total_learnings": len(LOCAL_MEMORY_SYSTEM.get('aprendizados', [])),
                "categories": ["restriction", "mandatory", "preference", "new_pattern", "correction", "formatting"]
            }
        }
        
        return {
            "status": "success",
            "dashboard": dashboard_data,
            "last_updated": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao obter dados de monitoramento: {e}")

@app.get("/api/agent/monitoring/search-events", tags=["Agente - Monitoramento"])
def get_search_events(limit: int = 20):
    """Retorna os eventos de busca mais recentes (sanitizados)"""
    try:
        if not MONITORING_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de monitoramento n√£o est√° ativo")
        events = list(MONITORING_SYSTEM.get('search_events', []))[-limit:]
        return {"status": "success", "events": events, "total": len(events)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao obter eventos de busca: {e}")

@app.get("/api/agent/monitoring/metrics", tags=["Agente - Monitoramento"])
def get_current_metrics():
    """Retorna m√©tricas atuais do sistema"""
    try:
        if not MONITORING_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de monitoramento n√£o est√° ativo")
            
        metrics = MONITORING_SYSTEM['metrics']
        
        return {
            "status": "success",
            "metrics": {
                "system": {
                    "memory_percent": psutil.virtual_memory().percent,
                    "cpu_percent": psutil.cpu_percent(),
                    "uptime_seconds": time.time() - metrics['system_uptime']
                },
                "requests": {
                    "total": metrics['requests_count'],
                    "errors_count": metrics['errors_count'],
                    "error_rate": round((metrics['errors_count'] / max(metrics['requests_count'], 1)) * 100, 2)
                },
                "performance": {
                    "avg_response_time": round(
                        sum(rt['response_time'] for rt in list(metrics['response_times'])[-10:]) /
                        max(len(list(metrics['response_times'])[-10:]), 1), 2
                    ),
                    "recent_requests": len(metrics['response_times'])
                },
                "business": {
                    "tokens_saved": metrics['tokens_saved'],
                    "versions_created": metrics['versions_created'],
                    "learning_events": metrics['learning_events'],
                    "search_count": metrics.get('search_count', 0)
                }
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao obter m√©tricas: {e}")

@app.get("/api/agent/monitoring/alerts", tags=["Agente - Monitoramento"])
def get_system_alerts():
    """Retorna alertas ativos do sistema"""
    try:
        if not MONITORING_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de monitoramento n√£o est√° ativo")
            
        alerts = MONITORING_SYSTEM.get('alerts', [])
        
        # Filtrar alertas das √∫ltimas 24 horas
        cutoff_time = datetime.now() - timedelta(hours=24)
        recent_alerts = [
            alert for alert in alerts 
            if datetime.fromisoformat(alert['timestamp']) > cutoff_time
        ]
        
        return {
            "status": "success",
            "alerts": recent_alerts,
            "total_alerts": len(alerts),
            "recent_alerts": len(recent_alerts),
            "alert_types": list(set(alert['type'] for alert in recent_alerts))
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao obter alertas: {e}")

@app.post("/api/agent/monitoring/clear-alerts", tags=["Agente - Monitoramento"])
def clear_system_alerts():
    """Limpa todos os alertas do sistema"""
    try:
        if not MONITORING_SYSTEM.get('active'):
            raise HTTPException(status_code=503, detail="Sistema de monitoramento n√£o est√° ativo")
            
        alerts_count = len(MONITORING_SYSTEM.get('alerts', []))
        MONITORING_SYSTEM['alerts'] = []
        
        return {
            "status": "success",
            "message": f"{alerts_count} alertas removidos",
            "cleared_count": alerts_count
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao limpar alertas: {e}")

@app.get("/api/agent/monitoring/health", tags=["Agente - Monitoramento"])
def get_health_check():
    """Health check completo do sistema"""
    try:
        health_status = {
            "overall": "healthy",
            "systems": {
                "monitoring": MONITORING_SYSTEM.get('active', False),
                "hybrid_memory": bool(LOCAL_MEMORY_SYSTEM),
                "versioning": VERSION_SYSTEM.get('active', False),
                "firestore": not firebase_mock_mode and bool(db),
                "gemini_ai": bool(GEMINI_CONFIGS)
            },
            "metrics": {
                "memory_usage": psutil.virtual_memory().percent,
                "cpu_usage": psutil.cpu_percent(),
                "uptime_hours": round((time.time() - MONITORING_SYSTEM.get('metrics', {}).get('system_uptime', time.time())) / 3600, 2)
            }
        }
        
        # Determinar status geral
        system_issues = [name for name, status in health_status["systems"].items() if not status]
        if system_issues:
            health_status["overall"] = "degraded" if len(system_issues) < 3 else "unhealthy"
            health_status["issues"] = system_issues
            
        return {
            "status": "success",
            "health": health_status,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "status": "error",
            "health": {"overall": "unhealthy", "error": str(e)},
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/agent/system-status", tags=["Agente - Sistema"])
def get_system_status():
    """Retorna o status do sistema h√≠brido de mem√≥ria e versionamento"""
    try:
        # Status do sistema de versionamento
        version_status = {
            "active": VERSION_SYSTEM.get('active', False),
            "total_versions": 0,
            "current_version": None,
            "latest_version": None
        }
        
        if VERSION_SYSTEM.get('active'):
            try:
                config_path = os.path.join(VERSION_SYSTEM['base_path'], 'config_versoes.json')
                if os.path.exists(config_path):
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = json.load(f)
                    version_status.update({
                        "total_versions": len(config.get('versions', [])),
                        "current_version": config.get('current_version'),
                        "latest_version": config.get('versions', [{}])[-1].get('id') if config.get('versions') else None
                    })
            except:
                pass
        
        return {
            "status": "success",
            "hybrid_system": {
                "active": bool(LOCAL_MEMORY_SYSTEM),
                "config_loaded": "config" in LOCAL_MEMORY_SYSTEM,
                "references_loaded": bool(LOCAL_MEMORY_SYSTEM.get('referencias_base')),
                "template_loaded": bool(LOCAL_MEMORY_SYSTEM.get('gabarito_template')),
                "contexts_loaded": len(LOCAL_MEMORY_SYSTEM.get('contextos', {})),
                "learnings_count": len(LOCAL_MEMORY_SYSTEM.get('aprendizados', []))
            },
            "version_system": version_status,
            "firestore": {
                "connected": not firebase_mock_mode and bool(db),
                "rules_loaded": bool(AGENT_RULES)
            },
            "memory_stats": {
                "total_references_chars": len(LOCAL_MEMORY_SYSTEM.get('referencias_base', '')),
                "total_template_chars": len(LOCAL_MEMORY_SYSTEM.get('gabarito_template', '')),
                "estimated_token_savings": "82%" if LOCAL_MEMORY_SYSTEM else "0%"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao obter status: {e}")

# --- Ponto de Entrada para Execu√ß√£o Local ---
if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8080)
