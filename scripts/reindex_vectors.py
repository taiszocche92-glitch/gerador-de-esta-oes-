"""
Script de reindexa√ß√£o de embeddings para o reposit√≥rio.

O que faz:
- L√™ `memoria/vectors/metadata.jsonl` para obter documentos e textos.
- Gera embeddings usando a API configurada por `gemini_client` + `google.generativeai` (tenta v√°rios m√©todos p√∫blicos).
- Salva `embeddings.npy`, `id_map.json` e `config.json` em `memoria/vectors/`.
- Faz backup do `embeddings.npy` anterior.

Uso:
    python scripts/reindex_vectors.py --model models/text-embedding-004 --batch 16

Notas:
- Requer chaves configuradas nas vari√°veis de ambiente (KEY_SLOTS no `gemini_client`).
- Se preferir outro provedor, modifique a fun√ß√£o `generate_embedding`.
"""

import os
import json
import time
import argparse
from pathlib import Path
import numpy as np

BASE = Path(__file__).resolve().parent.parent
VECTORS_DIR = BASE / 'memoria' / 'vectors'
METADATA_FILE = VECTORS_DIR / 'metadata.jsonl'
EMB_FILE = VECTORS_DIR / 'embeddings.npy'
ID_MAP_FILE = VECTORS_DIR / 'id_map.json'
CFG_FILE = VECTORS_DIR / 'config.json'

# Try to import clients
try:
    import sys
    sys.path.insert(0, str(BASE))  # Adicionar diret√≥rio raiz ao path
    from gemini_client import configure_first_available
except Exception as e:
    print(f"‚ö†Ô∏è Falha ao importar gemini_client: {e}")
    configure_first_available = None

try:
    import google.generativeai as genai
except Exception:
    genai = None


def load_metadata():
    docs = []
    if not METADATA_FILE.exists():
        print(f"Arquivo de metadata n√£o encontrado: {METADATA_FILE}")
        return docs
    with open(METADATA_FILE, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
                docs.append(obj)
            except Exception as e:
                print(f"‚ö†Ô∏è Falha ao ler linha {i} do metadata.jsonl: {e}")
    print(f"üìö Carregados {len(docs)} documentos do metadata.jsonl")
    return docs


def extract_text_from_meta(md):
    # Priorizar campos text/text_preview; sen√£o tentar meta.path
    text = None
    if not md:
        return ''
    if isinstance(md, dict):
        text = md.get('text') or md.get('text_preview')
        if text:
            return str(text)
        meta = md.get('meta') or {}
        path = meta.get('path') or meta.get('source')
        if path:
            p = Path(path)
            if not p.is_absolute():
                p = (BASE / path).resolve()
            try:
                if p.exists() and p.suffix.lower() in ['.txt', '.md', '.json']:
                    return p.read_text(encoding='utf-8')
            except Exception:
                pass
    return ''


def configure_api():
    used = None
    if configure_first_available:
        try:
            used = configure_first_available()
            print(f"üîë Chave configurada via gemini_client: {used}")
        except Exception as e:
            print(f"‚ö†Ô∏è gemini_client.configure_first_available falhou: {e}")
    else:
        print("‚ÑπÔ∏è gemini_client n√£o dispon√≠vel; tentativa de usar google.generativeai diretamente se instalado.")
        # tentar configurar genai diretamente a partir de vari√°veis de ambiente comuns
        try:
            if genai is None:
                print("‚ö†Ô∏è google.generativeai n√£o encontrado no ambiente (n√£o instalado).")
                # listar poss√≠veis vari√°veis de ambiente que podem conter chaves para ajudar o diagn√≥stico
                candidates = ['GEMINI_API_KEY_4'] + [f'GEMINI_API_KEY_{i}' for i in range(1,9) if i != 4] + ['GOOGLE_API_KEY', 'OPENAI_API_KEY']
                found = [k for k in candidates if os.getenv(k)]
                if found:
                    print(f"‚ÑπÔ∏è Vari√°veis de ambiente potencialmente presentes: {found}")
                else:
                    print("‚ÑπÔ∏è Nenhuma vari√°vel de ambiente de chave encontrada entre op√ß√µes comuns.")
                return None
            # se genai instalado, tentar configurar com a primeira vari√°vel de ambiente dispon√≠vel
            candidates = ['GEMINI_API_KEY_4'] + [f'GEMINI_API_KEY_{i}' for i in range(1,9) if i != 4] + ['GOOGLE_API_KEY', 'OPENAI_API_KEY']
            for var in candidates:
                val = os.getenv(var)
                if not val:
                    continue
                try:
                    if hasattr(genai, 'configure'):
                        getattr(genai, 'configure')(api_key=val)
                        print(f"üîë Chave configurada via vari√°vel de ambiente: {var}")
                        return var
                except Exception as e:
                    print(f"‚ö†Ô∏è Falha ao configurar genai com {var}: {e}")
                    continue
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao tentar configurar google.generativeai diretamente: {e}")
    return used


def generate_embedding_text(text, model_name=None):
    """Gera embedding para um texto. Retorna numpy array ou None."""
    # Tenta fun√ß√µes comuns do genai na ordem
    if genai is None:
        return None
    
    # 1) Tentativa principal: genai.embed_content (sabemos que funciona)
    try:
        # Usar getattr para evitar warning do linter sobre fun√ß√£o n√£o exportada
        embed_fn = getattr(genai, 'embed_content', None)
        if embed_fn:
            resp = embed_fn(model=model_name, content=text)
            if isinstance(resp, dict) and 'embedding' in resp:
                emb = resp['embedding']
                arr = np.array(emb, dtype=float)
                return arr
    except Exception as e:
        print(f"‚ÑπÔ∏è tentativa via genai.embed_content falhou: {e}")

    # 2) Tentativa alternativa: genai.embeddings.create
    try:
        emb_mod = getattr(genai, 'embeddings', None)
        if emb_mod:
            # muitos SDKs aceitam embeddings.create(model=..., input=[...])
            if hasattr(emb_mod, 'create'):
                try:
                    resp = emb_mod.create(model=model_name, input=[text])
                except TypeError:
                    try:
                        resp = emb_mod.create(input=[text], model=model_name)
                    except Exception:
                        resp = emb_mod.create(text)
                # extrair embedding da resposta
                emb = None
                # resposta pode ser um dict com 'data'
                if isinstance(resp, dict):
                    if 'data' in resp and resp['data']:
                        first = resp['data'][0]
                        if isinstance(first, dict):
                            emb = first.get('embedding') or first.get('embeddings')
                elif hasattr(resp, 'data'):
                    try:
                        first = resp.data[0]
                        if hasattr(first, 'embedding'):
                            emb = getattr(first, 'embedding')
                    except Exception:
                        pass
                if emb is not None:
                    arr = np.array(emb, dtype=float)
                    return arr
    except Exception as e:
        print(f"‚ÑπÔ∏è tentativa via genai.embeddings.create falhou: {e}")

    # 3) Tentativas por nomes de fun√ß√£o antigos/comuns
    fn_names = ['get_embeddings', 'get_embedding', 'embed_text', 'embed', 'embeddings']
    for name in fn_names:
        fn = getattr(genai, name, None)
        if not fn:
            continue
        try:
            # algumas APIs aceitam lista de inputs; aqui enviamos single
            try:
                resp = fn(model=model_name, input=text)
            except TypeError:
                # fallback argumentos alternativos
                try:
                    resp = fn(text, model=model_name)
                except Exception:
                    resp = fn(text)
            # extrair embedding
            emb = None
            if isinstance(resp, dict):
                if 'data' in resp and resp['data']:
                    first = resp['data'][0]
                    emb = first.get('embedding') if isinstance(first, dict) else None
                elif 'embedding' in resp:
                    emb = resp.get('embedding')
            elif hasattr(resp, 'embedding'):
                emb = getattr(resp, 'embedding')
            else:
                # √∫ltima tentativa: converter diretamente
                try:
                    arr = np.array(resp, dtype=float)
                    if arr.ndim == 1:
                        emb = arr.tolist()
                except Exception:
                    emb = None
            if emb is not None:
                arr = np.array(emb, dtype=float)
                return arr
        except Exception as e:
            # tentar pr√≥xima fun√ß√£o
            print(f"‚ÑπÔ∏è tentativa de {name} falhou: {e}")
            continue
    return None


def check_api_available(model_name=None, sample_text="teste de disponibilidade"):
    """Tenta gerar um embedding curto para verificar se a API de embeddings est√° dispon√≠vel.
    Retorna (ok: bool, info: str).
    """
    try:
        used = configure_api()
        emb = generate_embedding_text(sample_text, model_name=model_name)
        if emb is None:
            return False, "Nenhuma resposta de embedding retornada (verifique chaves/quota)."
        if isinstance(emb, np.ndarray) and emb.size > 0:
            return True, f"Embedding de teste gerado (dim={emb.shape[0]}) usando slot {used}"
        return False, "Resposta de embedding inv√°lida"
    except Exception as e:
        return False, str(e)


def backup_existing():
    if EMB_FILE.exists():
        ts = int(time.time())
        target = VECTORS_DIR / f"embeddings_backup_{ts}.npy"
        try:
            EMB_FILE.replace(target)
            print(f"üîÅ Backup criado: {target}")
        except Exception as e:
            print(f"‚ö†Ô∏è Falha ao criar backup do embeddings: {e}")


def main(args):
    docs = load_metadata()
    if not docs:
        print("‚ùå Nenhum documento para reindexar. Verifique memoria/vectors/metadata.jsonl")
        return

    used_slot = configure_api()

    # Preparar lista de documentos a indexar (suporta incremental)
    existing_ids = []
    if args.incremental and ID_MAP_FILE.exists():
        try:
            with open(ID_MAP_FILE, 'r', encoding='utf-8') as f:
                j = json.load(f)
                existing_ids = j.get('ids', []) if isinstance(j, dict) else j
            print(f"‚ÑπÔ∏è Modo incremental: {len(existing_ids)} ids existentes carregados")
        except Exception as e:
            print(f"‚ö†Ô∏è Falha ao carregar id_map existente: {e}")

    to_index = []
    for idx, md in enumerate(docs):
        doc_id = md.get('id') or md.get('meta', {}).get('path') or md.get('meta', {}).get('id') or str(idx)
        if args.incremental and doc_id in existing_ids:
            continue
        txt = extract_text_from_meta(md)
        to_index.append((doc_id, txt))

    if args.limit and args.limit > 0:
        to_index = to_index[:args.limit]

    if not to_index:
        print("‚ÑπÔ∏è Nenhum documento novo para indexar (modo incremental ou limite aplicado). Saindo.")
        return

    # Gerar embeddings iterativamente (batched simples)
    embeddings = []
    failed = []
    total = len(to_index)
    print(f"üöÄ Iniciando gera√ß√£o de embeddings para {total} documentos (modelo={args.model})")
    new_ids = []
    for i, (doc_id, txt) in enumerate(to_index):
        if not txt:
            print(f"‚ö†Ô∏è Documento {doc_id} tem texto vazio ‚Äî pulando")
            failed.append(doc_id)
            continue
        emb = generate_embedding_text(txt, model_name=args.model)
        if emb is None:
            print(f"‚ö†Ô∏è Falha ao gerar embedding para documento {doc_id}")
            failed.append(doc_id)
            time.sleep(0.1)
            continue
        embeddings.append(emb)
        new_ids.append(doc_id)
        if (i+1) % args.progress == 0 or i+1 == total:
            print(f"   ‚úÖ {i+1}/{total} embeddings gerados")
        if args.sleep_between > 0:
            time.sleep(args.sleep_between)

    if not embeddings:
        print("‚ùå Nenhum embedding gerado ‚Äî verifique credenciais/API.")
        return

    # Converter para array 2D
    try:
        new_emb_array = np.vstack([e.reshape(1, -1) for e in embeddings])
    except Exception as e:
        print(f"‚ùå Erro ao empilhar embeddings: {e}")
        return

    # Backup e salvar (se incremental, tentar anexar ao existente)
    try:
        if args.incremental and EMB_FILE.exists():
            existing = np.load(str(EMB_FILE))
            # checar compatibilidade de dimens√£o
            if existing.shape[1] != new_emb_array.shape[1]:
                print(f"‚ùå Dimens√£o incompat√≠vel: existing={existing.shape}, new={new_emb_array.shape}. Reindex completo necess√°rio.")
                return
            combined = np.vstack([existing, new_emb_array])
            backup_existing()
            np.save(str(EMB_FILE), combined)
            print(f"‚úÖ Embeddings anexados em: {EMB_FILE} (shape={combined.shape})")
            # atualizar id_map
            try:
                with open(ID_MAP_FILE, 'r', encoding='utf-8') as f:
                    j = json.load(f)
                    existing_ids_file = j.get('ids', []) if isinstance(j, dict) else j
            except Exception:
                existing_ids_file = []
            merged_ids = existing_ids_file + new_ids
            with open(ID_MAP_FILE, 'w', encoding='utf-8') as f:
                json.dump({'ids': merged_ids}, f, ensure_ascii=False, indent=2)
            print(f"‚úÖ id_map atualizado em: {ID_MAP_FILE}")
        else:
            backup_existing()
            np.save(str(EMB_FILE), new_emb_array)
            print(f"‚úÖ Embeddings salvos em: {EMB_FILE} (shape={new_emb_array.shape})")
            # Salvar id_map (os indices correspondem √†s linhas do embeddings.npy)
            try:
                with open(ID_MAP_FILE, 'w', encoding='utf-8') as f:
                    json.dump({'ids': new_ids}, f, ensure_ascii=False, indent=2)
                print(f"‚úÖ id_map salvo em: {ID_MAP_FILE}")
            except Exception as e:
                print(f"‚ö†Ô∏è Falha ao salvar id_map: {e}")
    except Exception as e:
        print(f"‚ùå Falha ao salvar embeddings: {e}")
        return

    # Salvar config simples
    # determinar tamanho final salvo
    try:
        final_count = None
        if args.incremental and EMB_FILE.exists():
            # recarregar para obter shape final
            final_arr = np.load(str(EMB_FILE))
            final_count = int(final_arr.shape[0])
        else:
            final_count = int(new_emb_array.shape[0])
    except Exception:
        final_count = None

    cfg = {
        'model': args.model,
        'generated_at': int(time.time()),
        'count': final_count
    }
    try:
        with open(CFG_FILE, 'w', encoding='utf-8') as f:
            json.dump(cfg, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ config salvo em: {CFG_FILE}")
    except Exception as e:
        print(f"‚ö†Ô∏è Falha ao salvar config: {e}")

    if failed:
        print(f"‚ö†Ô∏è Alguns documentos falharam ao gerar embedding: {len(failed)} itens. Exemplos de √≠ndices: {failed[:10]}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Reindexar vetores em memoria/vectors')
    parser.add_argument('--model', type=str, default=os.getenv('EMBEDDING_MODEL', 'models/text-embedding-004'), help='Nome do modelo de embeddings')
    parser.add_argument('--batch', type=int, default=1, help='Batch size (n√£o usado intensamente; chamado por item)')
    parser.add_argument('--sleep-between', type=float, default=0.0, help='Delay entre requisi√ß√µes (s)')
    parser.add_argument('--progress', type=int, default=10, help='Intervalo para logs de progresso')
    parser.add_argument('--skip-api-check', action='store_true', help='Pular verifica√ß√£o de disponibilidade da API')
    parser.add_argument('--incremental', action='store_true', help='Modo incremental: apenas novos documentos ser√£o indexados e anexados')
    parser.add_argument('--limit', type=int, default=0, help='Limitar n√∫mero de documentos a indexar (0 = sem limite)')
    args = parser.parse_args()
    if not args.skip_api_check:
        ok, info = check_api_available(args.model)
        if not ok:
            print(f"‚ùå Verifica√ß√£o de API falhou: {info}")
            print("Dica: rode com --skip-api-check se tiver certeza das credenciais ou corrija as chaves.")
            raise SystemExit(1)
        else:
            print(f"‚úÖ Verifica√ß√£o de API: {info}")
    main(args)
